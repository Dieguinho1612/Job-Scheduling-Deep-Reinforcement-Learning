{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e568fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Jobs_and_Machines.ipynb\n",
      "importing Jupyter notebook from States_and_Policies.ipynb\n",
      "importing Jupyter notebook from Global_Variables.ipynb\n",
      "importing Jupyter notebook from TransformerLayers.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, LSTM, Concatenate, LeakyReLU, Softmax, Dropout\n",
    "from keras.layers import Lambda, Flatten, Bidirectional, TimeDistributed, Reshape, MultiHeadAttention, LayerNormalization\n",
    "from keras.activations import tanh\n",
    "from keras.models import Model, Sequential\n",
    "import keras.backend\n",
    "import random\n",
    "from copy import copy\n",
    "#import necessary notebooks\n",
    "import import_ipynb\n",
    "from Jobs_and_Machines import *\n",
    "from States_and_Policies import *\n",
    "from TransformerLayers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6887f52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Job-Scheduling-Files'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change working directory\n",
    "os.chdir('D:\\\\Job-Scheduling-Files')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f7a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "n_min = 3\n",
    "\n",
    "m = 4\n",
    "m_min = 2\n",
    "\n",
    "DS_max = 1 #10\n",
    "DS_min = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311f2d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(DS_min,DS_max):\n",
    "    \n",
    "    data_dict = dict(((n_state,m_state),[[],[]]) \n",
    "                           for n_state in range(n_min,n+1) for m_state in range(m_min,m+1))\n",
    "    \n",
    "    #load data\n",
    "    for n_state in range(n_min, n+1):\n",
    "        for m_state in range(m_min, m+1):\n",
    "            x_j = []\n",
    "            x_m = []\n",
    "            y = []\n",
    "            for DS in [\"0\"*(2-len(str(i)))+str(i) for i in range(DS_min,DS_max+1)]:\n",
    "                training_data_path = f'Data/DataSet_{DS}/LSTM_Data_{DS}/{n_state}-jobs-{m_state}-machines_{DS}.pickle' #LSTM instead of Strd\n",
    "                with open(training_data_path, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                    machines_info = data[0][0][:,:,:-2].reshape((-1,n_state,m_state,4))\n",
    "                    jobs_info = data[0][0][:,:,-2:]\n",
    "                    x_m.append(machines_info)\n",
    "                    x_j.append(jobs_info)\n",
    "                    y.append(data[1][0])\n",
    "            data_dict[(n_state,m_state)][0].append(np.concatenate(x_m))\n",
    "            data_dict[(n_state,m_state)][0].append(np.concatenate(x_j))\n",
    "            data_dict[(n_state,m_state)][1].append(np.concatenate(y))\n",
    "            \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7006c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dict = load_data(DS_min,DS_max)\n",
    "validation_dict = load_data(98,98)\n",
    "#test_dict = load_data(99,99)\n",
    "test_dict = load_data(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4145d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into input and target and bring input into comprehensible form for LSTM\n",
    "x_train_list, y_train_list = [], []\n",
    "x_val_list, y_val_list = [], []\n",
    "x_test_list, y_test_list = [], []\n",
    "\n",
    "for key in training_dict:\n",
    "    #training data\n",
    "    x_train, y_train = training_dict[key]\n",
    "    x_train_list.append(x_train)\n",
    "    #x_train_list.append(runtimes_as_sequence(x_train))\n",
    "    #x_train_list.append(data_to_transformer_format(x_train))\n",
    "    y_train_list.append(y_train)\n",
    "    \n",
    "    #validation data\n",
    "    x_val, y_val = validation_dict[key]\n",
    "    x_val_list.append(x_val)\n",
    "    y_val_list.append(y_val)\n",
    "    \n",
    "    #test data\n",
    "    x_test, y_test = test_dict[key]\n",
    "    x_test_list.append(x_test)\n",
    "    y_test_list.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c6c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dropout muss noch hinzugef√ºgt werden\"\"\"\n",
    "inputs_machines = keras.Input(shape=(None,None,4), name=\"Machine_Info_with_Runtimes\")\n",
    "inputs_jobs = keras.Input(shape=(None,2), name=\"Jobs_Deadlines/Weights\")\n",
    "\n",
    "#FF on RT + Machine Info\n",
    "x_m = FeedForward(8,4, name=\"FF_Machines_Embedding\")(inputs_machines)\n",
    "#Transformer-Encoder with Self-Attention\n",
    "x_m = TimeDistributed(TransformerLayer(d_model=8,num_attention_heads=2,dff=8,self_att=True, name=\"Machines_for_every_JobRTs\"), name=\"Encoder\")(x_m)\n",
    "\n",
    "#FF on Deadline and Weight of Jobs\n",
    "x_j = FeedForward(8,4, name=\"FF_Jobs_Embedding\")(inputs_jobs)\n",
    "#Input Self-Attention of Transformer Decoder\n",
    "x_j = TransformerLayer(d_model=8,num_attention_heads=2,dff=8,self_att=True, name=\"Decoder_Input\")(x_j)\n",
    "\n",
    "#Merge all the information for every Job to pass it to Transformer Decoder Attention Part\n",
    "x_seq = Merge(name=\"Merge_every_Job_with_Machines\")(x_j,x_m) #We obtain a sequence of jobs encoded and with the machine information already integrated\n",
    "\n",
    "#Attention-Decoder for every Job\n",
    "x_seq = TimeDistributed(TransformerLayer(d_model=8,num_attention_heads=2,dff=8,self_att=False, name=\"Job_on_Machines\"), name=\"Decoder_Attention\")(x_seq)\n",
    "\n",
    "#Output Attention-Layer of Decoder\n",
    "x_seq = TransformerLayer(d_model=8,num_attention_heads=2,dff=8,self_att=True, name=\"Decoder_Output\")(x_seq)\n",
    "\n",
    "#Add Zero-Line for Machine Turn-Off\n",
    "x_seq = AddZeroLine(name=\"Add_Machine_Shut_Down\")(x_seq)\n",
    "\n",
    "#Pass Transformer-Output through LSTM\n",
    "lstm_out = Bidirectional(LSTM(16, name=\"Combine_Outputs\"), name=\"Bidir.LSTM\")(x_seq) #return_sequences=True\n",
    "#lstm_out = Bidirectional(LSTM(16))(lstm_out)\n",
    "\n",
    "#Apply Final FF on both                #maybe we could add a residual connection and a NormLayer here like in the Transformer Model\n",
    "val = FeedForward(16,16, name=\"Value_Embedding\")(x_seq)\n",
    "query = FeedForward(16,16, name=\"Query_Embedding\")(lstm_out)\n",
    "\n",
    "#Pointer\n",
    "output = Pointer(32, name=\"Pointer-Attentions\")(val,query)\n",
    "\n",
    "\"\"\"\n",
    "#Add Zero-Line for Machine Turn-Off\n",
    "print(x.shape)\n",
    "#zero_line = tf.zeros((x.shape[1],x.shape[2]))\n",
    "zero_line = tf.zeros_like(x[:,0:1,:])\n",
    "val = Concatenate(axis=1)([x,zero_line])\n",
    "print(val.shape)\n",
    "#Pass Transformer-Output through LSTM\n",
    "query = Bidirectional(LSTM(16))(x)\n",
    "#Apply Final FF on both                #maybe we could add a residual connection here like in the Transformer Model\n",
    "val = FeedForward(16,16)(val)\n",
    "query = FeedForward(16,16)(query)\n",
    "#Apply Pointer-NN to Hidden states\n",
    "output = Attention(32)(val,query)\n",
    "\"\"\"\n",
    "\n",
    "Transformer = keras.Model(inputs=[inputs_machines, inputs_jobs], outputs=output)\n",
    "\n",
    "\n",
    "#Pass final output through FF for Value to turn-off-machine\n",
    " #...\n",
    "#Apply Pointer-NN to Hidden states\n",
    " #...\n",
    "#Pass them through FF\n",
    " #...\n",
    "#Merge everything\n",
    "\n",
    "\n",
    "#Possible things to add:\n",
    "    #An own Weight matrix to find out the value for shutting-off the Machine\n",
    "    #Transform LSTM to Encoder-Decoder with Attention like in that Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a772442",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(Transformer, 'Transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7ae660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costs(y_true, y_pred):\n",
    "    \n",
    "    indices = keras.backend.argmax(y_pred, axis=1)\n",
    "    length = np.shape(indices)[0]\n",
    "    inv_values = keras.backend.eval(y_true)[np.arange(length),indices]\n",
    "    Q_factors = 1/inv_values\n",
    "    Q_factor = np.mean(Q_factors)\n",
    "    \n",
    "    Q_factor = (Q_factor - 1)*100\n",
    "    Q_factor = round(Q_factor,2) #vllt mal 10.000 nehmen, int verwandeln und durch 100 teilen\n",
    "    \n",
    "    return Q_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99edf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_with_Softmax(y_pred, y_true):\n",
    "    y_pred = Softmax()(y_pred)\n",
    "    y_true = Softmax()(y_true)\n",
    "    loss = keras.losses.MeanSquaredError()(y_pred,y_true)\n",
    "    #return loss\n",
    "    return (loss * 10e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0521675",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "Transformer.compile(\n",
    "        #loss = keras.losses.CategoricalCrossentropy(),\n",
    "        #loss = keras.losses.MeanSquaredError(),\n",
    "        loss = MSE_with_Softmax,\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "        run_eagerly=True,\n",
    "        metrics = [costs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df81f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We train on  18  different n-m-combinations.\n",
      "1/1 [==============================] - 8s 8s/step - loss: 68.5085 - costs: 34.5200\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 11s 11s/step - loss: 65.9201 - costs: 38.4000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 7s 7s/step - loss: 47.7322 - costs: 19.4300\n",
      "Epoch 4/4\n",
      "1/1 [==============================] - 6s 6s/step - loss: 132.7313 - costs: 38.1800\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 5s 5s/step - loss: 104.8291 - costs: 29.0000\n",
      "Epoch 6/6\n",
      "1/1 [==============================] - 6s 6s/step - loss: 48.0242 - costs: 44.0000\n",
      "Epoch 7/7\n",
      "1/1 [==============================] - 11s 11s/step - loss: 79.5336 - costs: 37.2500\n",
      "Epoch 8/8\n",
      "1/1 [==============================] - 7s 7s/step - loss: 39.0464 - costs: 32.8800\n",
      "Epoch 9/9\n",
      "1/1 [==============================] - 8s 8s/step - loss: 46.7698 - costs: 28.9100\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 195.7592 - costs: 35.5600\n",
      "Epoch 11/11\n",
      "1/1 [==============================] - 4s 4s/step - loss: 35.0727 - costs: 40.4100\n",
      "Epoch 12/12\n",
      "1/1 [==============================] - 3s 3s/step - loss: 174.9491 - costs: 25.8400\n",
      "Epoch 13/13\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.9191 - costs: 51.0500\n",
      "Epoch 14/14\n",
      "1/1 [==============================] - 4s 4s/step - loss: 229.6721 - costs: 44.1600\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 3s 3s/step - loss: 28.9712 - costs: 22.2600\n",
      "Epoch 16/16\n",
      "1/1 [==============================] - 5s 5s/step - loss: 87.3871 - costs: 19.3800\n",
      "Epoch 17/17\n",
      "1/1 [==============================] - 7s 7s/step - loss: 61.0200 - costs: 26.6500\n",
      "Epoch 18/18\n",
      "1/1 [==============================] - 6s 6s/step - loss: 52.2845 - costs: 16.1900\n",
      "Epoch 19/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"We train on \", len(x_train_list), \" different n-m-combinations.\")\n",
    "#x_train_orig, y_train_orig = np.copy(x_train_list), np.copy(y_train_list)\n",
    "ep=0\n",
    "for i in range(30):#range(50)\n",
    "    zipped_list = list(zip(x_train_list,y_train_list))\n",
    "    random.shuffle(zipped_list)\n",
    "    x_train_list, y_train_list = zip(*zipped_list)\n",
    "    for j in range(len(x_train_list)):\n",
    "        history = Transformer.fit(x_train_list[j], y_train_list[j], shuffle=True, batch_size=128000, epochs=ep+1, initial_epoch=ep) #validation_data=(x_val_list[j],y_val_list[j])) #callbacks=[my_val_callback]\n",
    "        ep = history.epoch[-1]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e00dec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/541\n",
      "1/1 [==============================] - 3s 3s/step - loss: 138.7464 - costs: 17.6400\n",
      "Epoch 542/542\n",
      "1/1 [==============================] - 7s 7s/step - loss: 25.9888 - costs: 7.6300\n",
      "Epoch 543/543\n",
      "1/1 [==============================] - 8s 8s/step - loss: 28.2314 - costs: 7.2600\n",
      "Epoch 544/544\n",
      "1/1 [==============================] - 4s 4s/step - loss: 50.2624 - costs: 4.7400\n",
      "Epoch 545/545\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.3631 - costs: 4.0200\n",
      "Epoch 546/546\n",
      "1/1 [==============================] - 3s 3s/step - loss: 21.5952 - costs: 9.5900\n",
      "Epoch 547/547\n",
      "1/1 [==============================] - 8s 8s/step - loss: 58.1834 - costs: 13.0900\n",
      "Epoch 548/548\n",
      "1/1 [==============================] - 3s 3s/step - loss: 178.6768 - costs: 18.1900\n",
      "Epoch 549/549\n",
      "1/1 [==============================] - 6s 6s/step - loss: 14.5614 - costs: 3.9500\n",
      "Epoch 550/550\n",
      "1/1 [==============================] - 6s 6s/step - loss: 35.1904 - costs: 7.6000\n",
      "Epoch 551/551\n",
      "1/1 [==============================] - 5s 5s/step - loss: 26.0913 - costs: 9.8100\n",
      "Epoch 552/552\n",
      "1/1 [==============================] - 4s 4s/step - loss: 52.0547 - costs: 8.3400\n",
      "Epoch 553/553\n",
      "1/1 [==============================] - 3s 3s/step - loss: 76.7042 - costs: 5.5000\n",
      "Epoch 554/554\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.8243 - costs: 7.2300\n",
      "Epoch 555/555\n",
      "1/1 [==============================] - 7s 7s/step - loss: 34.0919 - costs: 11.3000\n",
      "Epoch 556/556\n",
      "1/1 [==============================] - 38929s 38929s/step - loss: 70.0818 - costs: 11.7400\n",
      "Epoch 557/557\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.0709 - costs: 4.1400\n",
      "Epoch 558/558\n",
      "1/1 [==============================] - 6s 6s/step - loss: 28.9859 - costs: 3.6900\n",
      "Epoch 559/559\n",
      "1/1 [==============================] - 3s 3s/step - loss: 122.8849 - costs: 12.6400\n",
      "Epoch 560/560\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.0651 - costs: 3.9900\n",
      "Epoch 561/561\n",
      "1/1 [==============================] - 7s 7s/step - loss: 18.4835 - costs: 3.4400\n",
      "Epoch 562/562\n",
      "1/1 [==============================] - 3s 3s/step - loss: 70.4281 - costs: 4.7700\n",
      "Epoch 563/563\n",
      "1/1 [==============================] - 9s 9s/step - loss: 21.9252 - costs: 6.8500\n",
      "Epoch 564/564\n",
      "1/1 [==============================] - 4s 4s/step - loss: 51.7303 - costs: 7.8600\n",
      "Epoch 565/565\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.4721 - costs: 6.7500\n",
      "Epoch 566/566\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7325 - costs: 4.1400\n",
      "Epoch 567/567\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.0833 - costs: 8.4100\n",
      "Epoch 568/568\n",
      "1/1 [==============================] - 5s 5s/step - loss: 87.0726 - costs: 12.1800\n",
      "Epoch 569/569\n",
      "1/1 [==============================] - 8s 8s/step - loss: 36.1372 - costs: 9.8700\n",
      "Epoch 570/570\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.7274 - costs: 6.2400\n",
      "Epoch 571/571\n",
      "1/1 [==============================] - 6s 6s/step - loss: 20.2246 - costs: 3.4100\n",
      "Epoch 572/572\n",
      "1/1 [==============================] - 3s 3s/step - loss: 89.4244 - costs: 8.6900\n",
      "Epoch 573/573\n",
      "1/1 [==============================] - 5s 5s/step - loss: 22.5491 - costs: 8.5400\n",
      "Epoch 574/574\n",
      "1/1 [==============================] - 4s 4s/step - loss: 40.4514 - costs: 3.5900\n",
      "Epoch 575/575\n",
      "1/1 [==============================] - 9s 9s/step - loss: 42.1459 - costs: 9.9200\n",
      "Epoch 576/576\n",
      "1/1 [==============================] - 6s 6s/step - loss: 28.1910 - costs: 6.2400\n",
      "Epoch 577/577\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.2659 - costs: 3.2700\n",
      "Epoch 578/578\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.2863 - costs: 6.2000\n",
      "Epoch 579/579\n",
      "1/1 [==============================] - 5s 5s/step - loss: 22.2408 - costs: 8.6900\n",
      "Epoch 580/580\n",
      "1/1 [==============================] - 7s 7s/step - loss: 42.5307 - costs: 9.8100\n",
      "Epoch 581/581\n",
      "1/1 [==============================] - 4s 4s/step - loss: 43.0376 - costs: 6.5700\n",
      "Epoch 582/582\n",
      "1/1 [==============================] - 3s 3s/step - loss: 81.5567 - costs: 7.5300\n",
      "Epoch 583/583\n",
      "1/1 [==============================] - 3s 3s/step - loss: 112.2534 - costs: 11.2500\n",
      "Epoch 584/584\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.6699 - costs: 5.3000\n",
      "Epoch 585/585\n",
      "1/1 [==============================] - 6s 6s/step - loss: 30.2351 - costs: 9.1000\n",
      "Epoch 586/586\n",
      "1/1 [==============================] - 6s 6s/step - loss: 29.6010 - costs: 6.1900\n",
      "Epoch 587/587\n",
      "1/1 [==============================] - 6s 6s/step - loss: 22.4747 - costs: 3.3800\n",
      "Epoch 588/588\n",
      "1/1 [==============================] - 8s 8s/step - loss: 21.6406 - costs: 5.9500\n",
      "Epoch 589/589\n",
      "1/1 [==============================] - 4s 4s/step - loss: 39.6326 - costs: 3.3000\n",
      "Epoch 590/590\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.7933 - costs: 3.2300\n",
      "Epoch 591/591\n",
      "1/1 [==============================] - 3s 3s/step - loss: 58.3797 - costs: 4.1200\n",
      "Epoch 592/592\n",
      "1/1 [==============================] - 5s 5s/step - loss: 78.6284 - costs: 11.0900\n",
      "Epoch 593/593\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.4282 - costs: 6.7800\n",
      "Epoch 594/594\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.2601 - costs: 3.3400\n",
      "Epoch 595/595\n",
      "1/1 [==============================] - 4s 4s/step - loss: 28.9088 - costs: 4.0300\n",
      "Epoch 596/596\n",
      "1/1 [==============================] - 5s 5s/step - loss: 79.5373 - costs: 10.9400\n",
      "Epoch 597/597\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.4009 - costs: 3.1800\n",
      "Epoch 598/598\n",
      "1/1 [==============================] - 3s 3s/step - loss: 114.8578 - costs: 11.2400\n",
      "Epoch 599/599\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.0155 - costs: 7.3300\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 5s 5s/step - loss: 22.5399 - costs: 8.7100\n",
      "Epoch 601/601\n",
      "1/1 [==============================] - 7s 7s/step - loss: 25.6526 - costs: 7.1000\n",
      "Epoch 602/602\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.6290 - costs: 7.6400\n",
      "Epoch 603/603\n",
      "1/1 [==============================] - 8s 8s/step - loss: 34.7181 - costs: 11.5200\n",
      "Epoch 604/604\n",
      "1/1 [==============================] - 7s 7s/step - loss: 45.5683 - costs: 10.7400\n",
      "Epoch 605/605\n",
      "1/1 [==============================] - 6s 6s/step - loss: 24.0029 - costs: 3.3100\n",
      "Epoch 606/606\n",
      "1/1 [==============================] - 3s 3s/step - loss: 88.2753 - costs: 4.3700\n",
      "Epoch 607/607\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.5269 - costs: 2.8100\n",
      "Epoch 608/608\n",
      "1/1 [==============================] - 4s 4s/step - loss: 53.9905 - costs: 7.3900\n",
      "Epoch 609/609\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.5161 - costs: 3.7300\n",
      "Epoch 610/610\n",
      "1/1 [==============================] - 5s 5s/step - loss: 20.6191 - costs: 7.0500\n",
      "Epoch 611/611\n",
      "1/1 [==============================] - 3s 3s/step - loss: 166.6666 - costs: 11.6800\n",
      "Epoch 612/612\n",
      "1/1 [==============================] - 6s 6s/step - loss: 44.6185 - costs: 6.9200\n",
      "Epoch 613/613\n",
      "1/1 [==============================] - 5s 5s/step - loss: 28.4917 - costs: 8.2600\n",
      "Epoch 614/614\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.9079 - costs: 3.2900\n",
      "Epoch 615/615\n",
      "1/1 [==============================] - 3s 3s/step - loss: 66.5989 - costs: 5.3400\n",
      "Epoch 616/616\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.6767 - costs: 3.1400\n",
      "Epoch 617/617\n",
      "1/1 [==============================] - 5s 5s/step - loss: 64.5510 - costs: 10.3200\n",
      "Epoch 618/618\n",
      "1/1 [==============================] - 4s 4s/step - loss: 109.0395 - costs: 10.6500\n",
      "Epoch 619/619\n",
      "1/1 [==============================] - 11s 11s/step - loss: 40.7098 - costs: 9.1200\n",
      "Epoch 620/620\n",
      "1/1 [==============================] - 4s 4s/step - loss: 49.7673 - costs: 3.9500\n",
      "Epoch 621/621\n",
      "1/1 [==============================] - 5s 5s/step - loss: 32.9140 - costs: 3.3400\n",
      "Epoch 622/622\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.6021 - costs: 3.1900\n",
      "Epoch 623/623\n",
      "1/1 [==============================] - 3s 3s/step - loss: 81.3401 - costs: 6.5000\n",
      "Epoch 624/624\n",
      "1/1 [==============================] - 7s 7s/step - loss: 19.6574 - costs: 5.2100\n",
      "Epoch 625/625\n",
      "1/1 [==============================] - 6s 6s/step - loss: 25.6141 - costs: 5.4400\n",
      "Epoch 626/626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 15.6411 - costs: 6.2900\n",
      "Epoch 627/627\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.1904 - costs: 4.5600\n",
      "Epoch 628/628\n",
      "1/1 [==============================] - 4s 4s/step - loss: 45.7904 - costs: 6.2800\n",
      "Epoch 629/629\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.2196 - costs: 5.2200\n",
      "Epoch 630/630\n",
      "1/1 [==============================] - 7s 7s/step - loss: 31.8550 - costs: 8.0000\n",
      "Epoch 631/631\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1692 - costs: 3.1000\n",
      "Epoch 632/632\n",
      "1/1 [==============================] - 6s 6s/step - loss: 19.5708 - costs: 4.9200\n",
      "Epoch 633/633\n",
      "1/1 [==============================] - 3s 3s/step - loss: 59.6125 - costs: 4.3900\n",
      "Epoch 634/634\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.2479 - costs: 4.8000\n",
      "Epoch 635/635\n",
      "1/1 [==============================] - 4s 4s/step - loss: 42.7916 - costs: 6.0200\n",
      "Epoch 636/636\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.9604 - costs: 2.4700\n",
      "Epoch 637/637\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.5995 - costs: 2.5900\n",
      "Epoch 638/638\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27.5945 - costs: 2.9500\n",
      "Epoch 639/639\n",
      "1/1 [==============================] - 5s 5s/step - loss: 62.5431 - costs: 9.2400\n",
      "Epoch 640/640\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.6024 - costs: 4.7600\n",
      "Epoch 641/641\n",
      "1/1 [==============================] - 6s 6s/step - loss: 38.7973 - costs: 8.6800\n",
      "Epoch 642/642\n",
      "1/1 [==============================] - 5s 5s/step - loss: 19.7585 - costs: 7.1300\n",
      "Epoch 643/643\n",
      "1/1 [==============================] - 3s 3s/step - loss: 72.9626 - costs: 5.8000\n",
      "Epoch 644/644\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.8731 - costs: 5.2200\n",
      "Epoch 645/645\n",
      "1/1 [==============================] - 6s 6s/step - loss: 15.8285 - costs: 2.3400\n",
      "Epoch 646/646\n",
      "1/1 [==============================] - 6s 6s/step - loss: 24.7346 - costs: 5.3000\n",
      "Epoch 647/647\n",
      "1/1 [==============================] - 3s 3s/step - loss: 99.7533 - costs: 9.6000\n",
      "Epoch 648/648\n",
      "1/1 [==============================] - 6s 6s/step - loss: 25.6477 - costs: 7.1700\n",
      "Epoch 649/649\n",
      "1/1 [==============================] - 5s 5s/step - loss: 52.0399 - costs: 7.8600\n",
      "Epoch 650/650\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.6923 - costs: 2.2300\n",
      "Epoch 651/651\n",
      "1/1 [==============================] - 3s 3s/step - loss: 73.7487 - costs: 3.0800\n",
      "Epoch 652/652\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.4438 - costs: 4.8200\n",
      "Epoch 653/653\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27.8709 - costs: 2.7400\n",
      "Epoch 654/654\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.3713 - costs: 5.6500\n",
      "Epoch 655/655\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.4824 - costs: 2.3100\n",
      "Epoch 656/656\n",
      "1/1 [==============================] - 6s 6s/step - loss: 30.5593 - costs: 5.5400\n",
      "Epoch 657/657\n",
      "1/1 [==============================] - 3s 3s/step - loss: 132.3008 - costs: 11.4000\n",
      "Epoch 658/658\n",
      "1/1 [==============================] - 6s 6s/step - loss: 27.4242 - costs: 7.1100\n",
      "Epoch 659/659\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.9988 - costs: 5.8700\n",
      "Epoch 660/660\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.7851 - costs: 2.5800\n",
      "Epoch 661/661\n",
      "1/1 [==============================] - 6s 6s/step - loss: 39.0609 - costs: 8.5100\n",
      "Epoch 662/662\n",
      "1/1 [==============================] - 3s 3s/step - loss: 91.3006 - costs: 6.2900\n",
      "Epoch 663/663\n",
      "1/1 [==============================] - 5s 5s/step - loss: 22.6360 - costs: 7.5900\n",
      "Epoch 664/664\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.8503 - costs: 4.5600\n",
      "Epoch 665/665\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.8328 - costs: 2.6900\n",
      "Epoch 666/666\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.3813 - costs: 5.1200\n",
      "Epoch 667/667\n",
      "1/1 [==============================] - 3s 3s/step - loss: 96.4988 - costs: 9.0900\n",
      "Epoch 668/668\n",
      "1/1 [==============================] - 6s 6s/step - loss: 36.1634 - costs: 8.2900\n",
      "Epoch 669/669\n",
      "1/1 [==============================] - 6s 6s/step - loss: 23.4409 - costs: 5.3500\n",
      "Epoch 670/670\n",
      "1/1 [==============================] - 4s 4s/step - loss: 35.9987 - costs: 5.3500\n",
      "Epoch 671/671\n",
      "1/1 [==============================] - 6s 6s/step - loss: 25.3267 - costs: 6.9300\n",
      "Epoch 672/672\n",
      "1/1 [==============================] - 3s 3s/step - loss: 66.5288 - costs: 5.8800\n",
      "Epoch 673/673\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.7579 - costs: 4.0100\n",
      "Epoch 674/674\n",
      "1/1 [==============================] - 6s 6s/step - loss: 11.6573 - costs: 2.4200\n",
      "Epoch 675/675\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.1031 - costs: 2.5000\n",
      "Epoch 676/676\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.3418 - costs: 2.3800\n",
      "Epoch 677/677\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.8967 - costs: 4.7400\n",
      "Epoch 678/678\n",
      "1/1 [==============================] - 4s 4s/step - loss: 24.1331 - costs: 2.7100\n",
      "Epoch 679/679\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.5411 - costs: 5.0600\n",
      "Epoch 680/680\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.4500 - costs: 2.2700\n",
      "Epoch 681/681\n",
      "1/1 [==============================] - 3s 3s/step - loss: 44.7200 - costs: 3.3200\n",
      "Epoch 682/682\n",
      "1/1 [==============================] - 5s 5s/step - loss: 19.7341 - costs: 6.2000\n",
      "Epoch 683/683\n",
      "1/1 [==============================] - 5s 5s/step - loss: 63.5949 - costs: 8.6000\n",
      "Epoch 684/684\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.7545 - costs: 4.2400\n",
      "Epoch 685/685\n",
      "1/1 [==============================] - 6s 6s/step - loss: 9.8110 - costs: 2.3100\n",
      "Epoch 686/686\n",
      "1/1 [==============================] - 3s 3s/step - loss: 63.3118 - costs: 5.4600\n",
      "Epoch 687/687\n",
      "1/1 [==============================] - 6s 6s/step - loss: 33.8875 - costs: 7.3100\n",
      "Epoch 688/688\n",
      "1/1 [==============================] - 6s 6s/step - loss: 15.7332 - costs: 4.5000\n",
      "Epoch 689/689\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.2835 - costs: 4.2700\n",
      "Epoch 690/690\n",
      "1/1 [==============================] - 5s 5s/step - loss: 48.4066 - costs: 7.0300\n",
      "Epoch 691/691\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.3513 - costs: 5.6100\n",
      "Epoch 692/692\n",
      "1/1 [==============================] - 2s 2s/step - loss: 10.9604 - costs: 2.0900\n",
      "Epoch 693/693\n",
      "1/1 [==============================] - 5s 5s/step - loss: 23.4574 - costs: 2.4400\n",
      "Epoch 694/694\n",
      "1/1 [==============================] - 6s 6s/step - loss: 21.8091 - costs: 4.5400\n",
      "Epoch 695/695\n",
      "1/1 [==============================] - 3s 3s/step - loss: 83.2048 - costs: 7.2500\n",
      "Epoch 696/696\n",
      "1/1 [==============================] - 3s 3s/step - loss: 54.3277 - costs: 2.5300\n",
      "Epoch 697/697\n",
      "1/1 [==============================] - 4s 4s/step - loss: 22.3914 - costs: 2.5100\n",
      "Epoch 698/698\n",
      "1/1 [==============================] - 4s 4s/step - loss: 40.8476 - costs: 5.3900\n",
      "Epoch 699/699\n",
      "1/1 [==============================] - 5s 5s/step - loss: 7.2910 - costs: 2.2500\n",
      "Epoch 700/700\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.0983 - costs: 3.8600\n",
      "Epoch 701/701\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.1601 - costs: 6.1500\n",
      "Epoch 702/702\n",
      "1/1 [==============================] - 6s 6s/step - loss: 37.6358 - costs: 7.0600\n",
      "Epoch 703/703\n",
      "1/1 [==============================] - 3s 3s/step - loss: 154.5085 - costs: 11.3000\n",
      "Epoch 704/704\n",
      "1/1 [==============================] - 4s 4s/step - loss: 22.6699 - costs: 3.0000\n",
      "Epoch 705/705\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.7468 - costs: 3.6500\n",
      "Epoch 706/706\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.2945 - costs: 2.2200\n",
      "Epoch 707/707\n",
      "1/1 [==============================] - 2s 2s/step - loss: 11.1849 - costs: 2.4300\n",
      "Epoch 708/708\n",
      "1/1 [==============================] - 6s 6s/step - loss: 34.7485 - costs: 7.5300\n",
      "Epoch 709/709\n",
      "1/1 [==============================] - 3s 3s/step - loss: 91.3015 - costs: 6.7800\n",
      "Epoch 710/710\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.4664 - costs: 5.1200\n",
      "Epoch 711/711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 16.7523 - costs: 2.3300\n",
      "Epoch 712/712\n",
      "1/1 [==============================] - 6s 6s/step - loss: 26.9532 - costs: 7.4100\n",
      "Epoch 713/713\n",
      "1/1 [==============================] - 5s 5s/step - loss: 21.0432 - costs: 7.0400\n",
      "Epoch 714/714\n",
      "1/1 [==============================] - 3s 3s/step - loss: 53.5315 - costs: 3.1000\n",
      "Epoch 715/715\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.6234 - costs: 4.5800\n",
      "Epoch 716/716\n",
      "1/1 [==============================] - 6s 6s/step - loss: 24.0458 - costs: 5.1000\n",
      "Epoch 717/717\n",
      "1/1 [==============================] - 6s 6s/step - loss: 17.3013 - costs: 4.7300\n",
      "Epoch 718/718\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.2413 - costs: 2.7200\n",
      "Epoch 719/719\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.3434 - costs: 5.2600\n",
      "Epoch 720/720\n",
      "1/1 [==============================] - 5s 5s/step - loss: 68.2722 - costs: 8.2600\n",
      "Epoch 721/721\n",
      "1/1 [==============================] - 5s 5s/step - loss: 63.6746 - costs: 8.0500\n",
      "Epoch 722/722\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.2892 - costs: 5.0700\n",
      "Epoch 723/723\n",
      "1/1 [==============================] - 6s 6s/step - loss: 10.0136 - costs: 2.2100\n",
      "Epoch 724/724\n",
      "1/1 [==============================] - 7s 7s/step - loss: 15.6807 - costs: 4.3200\n",
      "Epoch 725/725\n",
      "1/1 [==============================] - 4s 4s/step - loss: 86.2793 - costs: 7.4500\n",
      "Epoch 726/726\n",
      "1/1 [==============================] - 6s 6s/step - loss: 12.7589 - costs: 3.9000\n",
      "Epoch 727/727\n",
      "1/1 [==============================] - 6s 6s/step - loss: 12.9860 - costs: 2.2000\n",
      "Epoch 728/728\n",
      "1/1 [==============================] - 10s 10s/step - loss: 34.9622 - costs: 2.5600\n",
      "Epoch 729/729\n",
      "1/1 [==============================] - 6s 6s/step - loss: 22.3697 - costs: 4.3900\n",
      "Epoch 730/730\n",
      "1/1 [==============================] - 6s 6s/step - loss: 32.6226 - costs: 7.2100\n",
      "Epoch 731/731\n",
      "1/1 [==============================] - 6s 6s/step - loss: 23.2544 - costs: 6.5400\n",
      "Epoch 732/732\n",
      "1/1 [==============================] - 4s 4s/step - loss: 33.4243 - costs: 4.5100\n",
      "Epoch 733/733\n",
      "1/1 [==============================] - 3s 3s/step - loss: 63.9332 - costs: 4.9500\n",
      "Epoch 734/734\n",
      "1/1 [==============================] - 3s 3s/step - loss: 51.3691 - costs: 2.6100\n",
      "Epoch 735/735\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.6713 - costs: 3.2100\n",
      "Epoch 736/736\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.9884 - costs: 1.9300\n",
      "Epoch 737/737\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.8231 - costs: 5.9000\n",
      "Epoch 738/738\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.7232 - costs: 2.5300\n",
      "Epoch 739/739\n",
      "1/1 [==============================] - 4s 4s/step - loss: 44.2674 - costs: 5.6700\n",
      "Epoch 740/740\n",
      "1/1 [==============================] - 7s 7s/step - loss: 18.3590 - costs: 4.4700\n",
      "Epoch 741/741\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2855 - costs: 2.0600\n",
      "Epoch 742/742\n",
      "1/1 [==============================] - 5s 5s/step - loss: 62.1155 - costs: 7.8100\n",
      "Epoch 743/743\n",
      "1/1 [==============================] - 4s 4s/step - loss: 20.5126 - costs: 2.5900\n",
      "Epoch 744/744\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.2613 - costs: 2.0200\n",
      "Epoch 745/745\n",
      "1/1 [==============================] - 3s 3s/step - loss: 40.8963 - costs: 2.7300\n",
      "Epoch 746/746\n",
      "1/1 [==============================] - 8s 8s/step - loss: 22.6748 - costs: 6.1500\n",
      "Epoch 747/747\n",
      "1/1 [==============================] - 4s 4s/step - loss: 79.5955 - costs: 7.1600\n",
      "Epoch 748/748\n",
      "1/1 [==============================] - 8s 8s/step - loss: 15.7083 - costs: 1.9900\n",
      "Epoch 749/749\n",
      "1/1 [==============================] - 6s 6s/step - loss: 9.8637 - costs: 3.5700\n",
      "Epoch 750/750\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.3182 - costs: 4.1200\n",
      "Epoch 751/751\n",
      "1/1 [==============================] - 6s 6s/step - loss: 14.1551 - costs: 2.0900\n",
      "Epoch 752/752\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.6806 - costs: 5.5400\n",
      "Epoch 753/753\n",
      "1/1 [==============================] - 3s 3s/step - loss: 60.7222 - costs: 4.4900\n",
      "Epoch 754/754\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.8734 - costs: 5.5200\n",
      "Epoch 755/755\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.9111 - costs: 4.0100\n",
      "Epoch 756/756\n",
      "1/1 [==============================] - 7s 7s/step - loss: 30.6677 - costs: 6.5000\n",
      "Epoch 757/757\n",
      "1/1 [==============================] - 6s 6s/step - loss: 21.0233 - costs: 2.2400\n",
      "Epoch 758/758\n",
      "1/1 [==============================] - 8s 8s/step - loss: 8.4027 - costs: 1.9400\n",
      "Epoch 759/759\n",
      "1/1 [==============================] - 6s 6s/step - loss: 34.6695 - costs: 7.0300\n",
      "Epoch 760/760\n",
      "1/1 [==============================] - 6s 6s/step - loss: 24.1618 - costs: 6.0000\n",
      "Epoch 761/761\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.5208 - costs: 1.8800\n",
      "Epoch 762/762\n",
      "1/1 [==============================] - 3s 3s/step - loss: 87.7945 - costs: 7.5500\n",
      "Epoch 763/763\n",
      "1/1 [==============================] - 7s 7s/step - loss: 19.3867 - costs: 4.1200\n",
      "Epoch 764/764\n",
      "1/1 [==============================] - 6s 6s/step - loss: 15.3442 - costs: 5.0900\n",
      "Epoch 765/765\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.0406 - costs: 3.3600\n",
      "Epoch 766/766\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.7406 - costs: 4.6900\n",
      "Epoch 767/767\n",
      "1/1 [==============================] - 6s 6s/step - loss: 21.4734 - costs: 2.1100\n",
      "Epoch 768/768\n",
      "1/1 [==============================] - 6s 6s/step - loss: 46.1416 - costs: 6.2100\n",
      "Epoch 769/769\n",
      "1/1 [==============================] - 10s 10s/step - loss: 32.2512 - costs: 3.9100\n",
      "Epoch 770/770\n",
      "1/1 [==============================] - 14s 14s/step - loss: 14.2111 - costs: 3.7400\n",
      "Epoch 771/771\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.6318 - costs: 3.5900\n",
      "Epoch 772/772\n",
      "1/1 [==============================] - 3s 3s/step - loss: 47.7293 - costs: 2.3000\n",
      "Epoch 773/773\n",
      "1/1 [==============================] - 6s 6s/step - loss: 10.1287 - costs: 1.9500\n",
      "Epoch 774/774\n",
      "1/1 [==============================] - 3s 3s/step - loss: 64.3364 - costs: 5.6200\n",
      "Epoch 775/775\n",
      "1/1 [==============================] - 6s 6s/step - loss: 8.6025 - costs: 2.0100\n",
      "Epoch 776/776\n",
      "1/1 [==============================] - 7s 7s/step - loss: 38.0086 - costs: 7.2200\n",
      "Epoch 777/777\n",
      "1/1 [==============================] - 9s 9s/step - loss: 11.1358 - costs: 2.1900\n",
      "Epoch 778/778\n",
      "1/1 [==============================] - 7s 7s/step - loss: 18.2678 - costs: 2.3900\n",
      "Epoch 779/779\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.5849 - costs: 4.3400\n",
      "Epoch 780/780\n",
      "1/1 [==============================] - 3s 3s/step - loss: 61.4571 - costs: 5.0600\n",
      "Epoch 781/781\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.4051 - costs: 1.8200\n",
      "Epoch 782/782\n",
      "1/1 [==============================] - 5s 5s/step - loss: 46.0834 - costs: 6.4700\n",
      "Epoch 783/783\n",
      "1/1 [==============================] - 7s 7s/step - loss: 18.0535 - costs: 3.8500\n",
      "Epoch 784/784\n",
      "1/1 [==============================] - 6s 6s/step - loss: 10.7379 - costs: 1.9100\n",
      "Epoch 785/785\n",
      "1/1 [==============================] - 12s 12s/step - loss: 20.5265 - costs: 5.4800\n",
      "Epoch 786/786\n",
      "1/1 [==============================] - 5s 5s/step - loss: 32.3694 - costs: 4.0200\n",
      "Epoch 787/787\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.8505 - costs: 5.3700\n",
      "Epoch 788/788\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.6180 - costs: 3.8700\n",
      "Epoch 789/789\n",
      "1/1 [==============================] - 4s 4s/step - loss: 81.4328 - costs: 6.6000\n",
      "Epoch 790/790\n",
      "1/1 [==============================] - 3s 3s/step - loss: 61.5616 - costs: 2.4200\n",
      "Epoch 791/791\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.1088 - costs: 3.1900\n",
      "Epoch 792/792\n",
      "1/1 [==============================] - 13s 13s/step - loss: 14.8211 - costs: 3.8200\n",
      "Epoch 793/793\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.5649 - costs: 4.1700\n",
      "Epoch 794/794\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.1064 - costs: 2.1600\n",
      "Epoch 795/795\n",
      "1/1 [==============================] - 7s 7s/step - loss: 32.6994 - costs: 6.3100\n",
      "Epoch 796/796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 8.5583 - costs: 2.3400\n",
      "Epoch 797/797\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.3200 - costs: 6.1900\n",
      "Epoch 798/798\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.9632 - costs: 4.4700\n",
      "Epoch 799/799\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.5682 - costs: 4.2200\n",
      "Epoch 800/800\n",
      "1/1 [==============================] - 5s 5s/step - loss: 87.4570 - costs: 8.4500\n",
      "Epoch 801/801\n",
      "1/1 [==============================] - 3s 3s/step - loss: 53.4475 - costs: 4.0800\n",
      "Epoch 802/802\n",
      "1/1 [==============================] - 4s 4s/step - loss: 107.6719 - costs: 8.6600\n",
      "Epoch 803/803\n",
      "1/1 [==============================] - 8s 8s/step - loss: 29.7935 - costs: 4.3000\n",
      "Epoch 804/804\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.9052 - costs: 1.8300\n",
      "Epoch 805/805\n",
      "1/1 [==============================] - 4s 4s/step - loss: 43.5778 - costs: 3.0100\n",
      "Epoch 806/806\n",
      "1/1 [==============================] - 14s 14s/step - loss: 28.6200 - costs: 4.9900\n",
      "Epoch 807/807\n",
      "1/1 [==============================] - 16s 16s/step - loss: 38.9813 - costs: 7.8100\n",
      "Epoch 808/808\n",
      "1/1 [==============================] - 5s 5s/step - loss: 21.8439 - costs: 2.7400\n",
      "Epoch 809/809\n",
      "1/1 [==============================] - 7s 7s/step - loss: 23.1812 - costs: 5.0400\n",
      "Epoch 810/810\n",
      "1/1 [==============================] - 3s 3s/step - loss: 97.3325 - costs: 7.4600\n",
      "Epoch 811/811\n",
      "1/1 [==============================] - 2s 2s/step - loss: 14.8083 - costs: 2.3900\n",
      "Epoch 812/812\n",
      "1/1 [==============================] - 3s 3s/step - loss: 21.1377 - costs: 5.2000\n",
      "Epoch 813/813\n",
      "1/1 [==============================] - 6s 6s/step - loss: 20.4472 - costs: 4.2900\n",
      "Epoch 814/814\n",
      "1/1 [==============================] - 6s 6s/step - loss: 17.2150 - costs: 4.0700\n",
      "Epoch 815/815\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.4090 - costs: 2.3200\n",
      "Epoch 816/816\n",
      "1/1 [==============================] - 8s 8s/step - loss: 12.2638 - costs: 3.3800\n",
      "Epoch 817/817\n",
      "1/1 [==============================] - 6s 6s/step - loss: 10.8842 - costs: 2.1700\n",
      "Epoch 818/818\n",
      "1/1 [==============================] - 5s 5s/step - loss: 40.6671 - costs: 5.3900\n",
      "Epoch 819/819\n",
      "1/1 [==============================] - 5s 5s/step - loss: 7.8010 - costs: 2.4600\n",
      "Epoch 820/820\n",
      "1/1 [==============================] - 3s 3s/step - loss: 75.5903 - costs: 6.5500\n",
      "Epoch 821/821\n",
      "1/1 [==============================] - 5s 5s/step - loss: 20.5541 - costs: 6.2600\n",
      "Epoch 822/822\n",
      "1/1 [==============================] - 13s 13s/step - loss: 29.0226 - costs: 6.4800\n",
      "Epoch 823/823\n",
      "1/1 [==============================] - 3s 3s/step - loss: 39.5159 - costs: 2.9300\n",
      "Epoch 824/824\n",
      "1/1 [==============================] - 5s 5s/step - loss: 52.2466 - costs: 6.9100\n",
      "Epoch 825/825\n",
      "1/1 [==============================] - 7s 7s/step - loss: 32.2569 - costs: 6.3300\n",
      "Epoch 826/826\n",
      "1/1 [==============================] - 14s 14s/step - loss: 18.5046 - costs: 3.8100\n",
      "Epoch 827/827\n",
      "1/1 [==============================] - 4s 4s/step - loss: 25.4198 - costs: 2.0700\n",
      "Epoch 828/828\n",
      "1/1 [==============================] - 3s 3s/step - loss: 75.7688 - costs: 6.1300\n",
      "Epoch 829/829\n",
      "1/1 [==============================] - 4s 4s/step - loss: 28.6077 - costs: 2.1100\n",
      "Epoch 830/830\n",
      "1/1 [==============================] - 3s 3s/step - loss: 76.2454 - costs: 6.0300\n",
      "Epoch 831/831\n",
      "1/1 [==============================] - 14s 14s/step - loss: 14.2149 - costs: 3.5900\n",
      "Epoch 832/832\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.2841 - costs: 1.8000\n",
      "Epoch 833/833\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.0018 - costs: 3.1300\n",
      "Epoch 834/834\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.5615 - costs: 3.6300\n",
      "Epoch 835/835\n",
      "1/1 [==============================] - 5s 5s/step - loss: 28.4950 - costs: 3.9300\n",
      "Epoch 836/836\n",
      "1/1 [==============================] - 12s 12s/step - loss: 20.8036 - costs: 5.6200\n",
      "Epoch 837/837\n",
      "1/1 [==============================] - 7s 7s/step - loss: 10.5970 - costs: 1.8900\n",
      "Epoch 838/838\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.1622 - costs: 4.0000\n",
      "Epoch 839/839\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.6175 - costs: 5.1600\n",
      "Epoch 840/840\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.1427 - costs: 1.9700\n",
      "Epoch 841/841\n",
      "1/1 [==============================] - 12s 12s/step - loss: 45.6137 - costs: 6.3200\n",
      "Epoch 842/842\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.2128 - costs: 1.8400\n",
      "Epoch 843/843\n",
      "1/1 [==============================] - 7s 7s/step - loss: 30.0843 - costs: 6.1200\n",
      "Epoch 844/844\n",
      "1/1 [==============================] - 3s 3s/step - loss: 38.5354 - costs: 2.0900\n",
      "Epoch 845/845\n",
      "1/1 [==============================] - 11s 11s/step - loss: 18.3130 - costs: 3.8800\n",
      "Epoch 846/846\n",
      "1/1 [==============================] - 5s 5s/step - loss: 51.6467 - costs: 4.3200\n",
      "Epoch 847/847\n",
      "1/1 [==============================] - 5s 5s/step - loss: 27.3450 - costs: 3.8400\n",
      "Epoch 848/848\n",
      "1/1 [==============================] - 7s 7s/step - loss: 28.5010 - costs: 5.8200\n",
      "Epoch 849/849\n",
      "1/1 [==============================] - 4s 4s/step - loss: 68.3910 - costs: 5.8900\n",
      "Epoch 850/850\n",
      "1/1 [==============================] - 8s 8s/step - loss: 8.0150 - costs: 1.7900\n",
      "Epoch 851/851\n",
      "1/1 [==============================] - 6s 6s/step - loss: 39.2188 - costs: 5.4900\n",
      "Epoch 852/852\n",
      "1/1 [==============================] - 7s 7s/step - loss: 19.5182 - costs: 5.1700\n",
      "Epoch 853/853\n",
      "1/1 [==============================] - 9s 9s/step - loss: 18.3662 - costs: 1.9700\n",
      "Epoch 854/854\n",
      "1/1 [==============================] - 6s 6s/step - loss: 59.1644 - costs: 2.2800\n",
      "Epoch 855/855\n",
      "1/1 [==============================] - 6s 6s/step - loss: 11.0127 - costs: 1.8600\n",
      "Epoch 856/856\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.8112 - costs: 1.8400\n",
      "Epoch 857/857\n",
      "1/1 [==============================] - 16s 16s/step - loss: 14.0029 - costs: 3.6000\n",
      "Epoch 858/858\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.9229 - costs: 4.9000\n",
      "Epoch 859/859\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.5764 - costs: 3.3500\n",
      "Epoch 860/860\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.4696 - costs: 2.9700\n",
      "Epoch 861/861\n",
      "1/1 [==============================] - 6s 6s/step - loss: 25.7240 - costs: 4.2900\n",
      "Epoch 862/862\n",
      "1/1 [==============================] - 10s 10s/step - loss: 21.0243 - costs: 2.5600\n",
      "Epoch 863/863\n",
      "1/1 [==============================] - 3s 3s/step - loss: 76.8313 - costs: 5.8800\n",
      "Epoch 864/864\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.7594 - costs: 3.9800\n",
      "Epoch 865/865\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.7562 - costs: 5.0200\n",
      "Epoch 866/866\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.4529 - costs: 3.0400\n",
      "Epoch 867/867\n",
      "1/1 [==============================] - 7s 7s/step - loss: 18.3192 - costs: 3.8300\n",
      "Epoch 868/868\n",
      "1/1 [==============================] - 12s 12s/step - loss: 9.6605 - costs: 1.8900\n",
      "Epoch 869/869\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.2388 - costs: 3.5200\n",
      "Epoch 870/870\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.7820 - costs: 3.7200\n",
      "Epoch 871/871\n",
      "1/1 [==============================] - 6s 6s/step - loss: 40.2317 - costs: 5.8200\n",
      "Epoch 872/872\n",
      "1/1 [==============================] - 10s 10s/step - loss: 30.9690 - costs: 2.1700\n",
      "Epoch 873/873\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.3972 - costs: 3.9500\n",
      "Epoch 874/874\n",
      "1/1 [==============================] - 5s 5s/step - loss: 27.8148 - costs: 3.7000\n",
      "Epoch 875/875\n",
      "1/1 [==============================] - 6s 6s/step - loss: 26.6832 - costs: 5.6200\n",
      "Epoch 876/876\n",
      "1/1 [==============================] - 3s 3s/step - loss: 51.9582 - costs: 4.1300\n",
      "Epoch 877/877\n",
      "1/1 [==============================] - 12s 12s/step - loss: 10.6054 - costs: 1.8600\n",
      "Epoch 878/878\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.7180 - costs: 1.8300\n",
      "Epoch 879/879\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.6534 - costs: 1.8100\n",
      "Epoch 880/880\n",
      "1/1 [==============================] - 3s 3s/step - loss: 32.7655 - costs: 2.1500\n",
      "Epoch 881/881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 84.4239 - costs: 6.6900\n",
      "Epoch 882/882\n",
      "1/1 [==============================] - 13s 13s/step - loss: 23.3881 - costs: 5.3500\n",
      "Epoch 883/883\n",
      "1/1 [==============================] - 3s 3s/step - loss: 50.8061 - costs: 4.2900\n",
      "Epoch 884/884\n",
      "1/1 [==============================] - 4s 4s/step - loss: 26.1705 - costs: 3.6700\n",
      "Epoch 885/885\n",
      "1/1 [==============================] - 13s 13s/step - loss: 26.5652 - costs: 5.3800\n",
      "Epoch 886/886\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.6089 - costs: 4.8900\n",
      "Epoch 887/887\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27.0819 - costs: 1.9900\n",
      "Epoch 888/888\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.7501 - costs: 4.7300\n",
      "Epoch 889/889\n",
      "1/1 [==============================] - 12s 12s/step - loss: 18.0167 - costs: 3.4700\n",
      "Epoch 890/890\n",
      "1/1 [==============================] - 11s 11s/step - loss: 12.2125 - costs: 2.1200\n",
      "Epoch 891/891\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.7423 - costs: 1.9800\n",
      "Epoch 892/892\n",
      "1/1 [==============================] - 5s 5s/step - loss: 38.7343 - costs: 5.2800\n",
      "Epoch 893/893\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.2340 - costs: 3.3500\n",
      "Epoch 894/894\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.2847 - costs: 3.6200\n",
      "Epoch 895/895\n",
      "1/1 [==============================] - 15s 15s/step - loss: 12.5819 - costs: 3.4500\n",
      "Epoch 896/896\n",
      "1/1 [==============================] - 6s 6s/step - loss: 10.0588 - costs: 1.9300\n",
      "Epoch 897/897\n",
      "1/1 [==============================] - 3s 3s/step - loss: 64.8041 - costs: 5.5100\n",
      "Epoch 898/898\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.4412 - costs: 2.7700\n",
      "Epoch 899/899\n",
      "1/1 [==============================] - 3s 3s/step - loss: 36.9257 - costs: 1.9000\n",
      "Epoch 900/900\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.3608 - costs: 1.8200\n",
      "Epoch 901/901\n",
      "1/1 [==============================] - 11s 11s/step - loss: 9.7618 - costs: 1.8500\n",
      "Epoch 902/902\n",
      "1/1 [==============================] - 6s 6s/step - loss: 21.6994 - costs: 3.9500\n",
      "Epoch 903/903\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.1729 - costs: 3.9800\n",
      "Epoch 904/904\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.9743 - costs: 1.7000\n",
      "Epoch 905/905\n",
      "1/1 [==============================] - 4s 4s/step - loss: 37.7394 - costs: 4.3900\n",
      "Epoch 906/906\n",
      "1/1 [==============================] - 5s 5s/step - loss: 5.9231 - costs: 1.7900\n",
      "Epoch 907/907\n",
      "1/1 [==============================] - 13s 13s/step - loss: 6.8312 - costs: 1.7500\n",
      "Epoch 908/908\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.9153 - costs: 3.3100\n",
      "Epoch 909/909\n",
      "1/1 [==============================] - 6s 6s/step - loss: 24.0924 - costs: 5.4600\n",
      "Epoch 910/910\n",
      "1/1 [==============================] - 3s 3s/step - loss: 82.6507 - costs: 6.6900\n",
      "Epoch 911/911\n",
      "1/1 [==============================] - 3s 3s/step - loss: 34.1522 - costs: 2.1400\n",
      "Epoch 912/912\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.1634 - costs: 2.8000\n",
      "Epoch 913/913\n",
      "1/1 [==============================] - 12s 12s/step - loss: 37.5205 - costs: 5.3100\n",
      "Epoch 914/914\n",
      "1/1 [==============================] - 3s 3s/step - loss: 49.9147 - costs: 3.8300\n",
      "Epoch 915/915\n",
      "1/1 [==============================] - 4s 4s/step - loss: 26.5356 - costs: 1.9200\n",
      "Epoch 916/916\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.8497 - costs: 4.6100\n",
      "Epoch 917/917\n",
      "1/1 [==============================] - 11s 11s/step - loss: 12.2780 - costs: 3.3700\n",
      "Epoch 918/918\n",
      "1/1 [==============================] - 9s 9s/step - loss: 25.2591 - costs: 5.1600\n",
      "Epoch 919/919\n",
      "1/1 [==============================] - 5s 5s/step - loss: 36.4206 - costs: 5.2200\n",
      "Epoch 920/920\n",
      "1/1 [==============================] - 13s 13s/step - loss: 12.0344 - costs: 3.3300\n",
      "Epoch 921/921\n",
      "1/1 [==============================] - 3s 3s/step - loss: 46.7204 - costs: 3.7500\n",
      "Epoch 922/922\n",
      "1/1 [==============================] - 4s 4s/step - loss: 24.3041 - costs: 3.4200\n",
      "Epoch 923/923\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.1903 - costs: 3.4200\n",
      "Epoch 924/924\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.8504 - costs: 1.7800\n",
      "Epoch 925/925\n",
      "1/1 [==============================] - 12s 12s/step - loss: 13.8091 - costs: 4.3900\n",
      "Epoch 926/926\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.2605 - costs: 2.7600\n",
      "Epoch 927/927\n",
      "1/1 [==============================] - 11s 11s/step - loss: 7.9048 - costs: 1.8200\n",
      "Epoch 928/928\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.2922 - costs: 1.8100\n",
      "Epoch 929/929\n",
      "1/1 [==============================] - 5s 5s/step - loss: 6.7485 - costs: 1.8100\n",
      "Epoch 930/930\n",
      "1/1 [==============================] - 6s 6s/step - loss: 23.2321 - costs: 5.1300\n",
      "Epoch 931/931\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.3379 - costs: 1.6700\n",
      "Epoch 932/932\n",
      "1/1 [==============================] - 3s 3s/step - loss: 29.2573 - costs: 2.1600\n",
      "Epoch 933/933\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.1071 - costs: 3.1500\n",
      "Epoch 934/934\n",
      "1/1 [==============================] - 12s 12s/step - loss: 19.4870 - costs: 3.8300\n",
      "Epoch 935/935\n",
      "1/1 [==============================] - 3s 3s/step - loss: 80.2959 - costs: 6.3500\n",
      "Epoch 936/936\n",
      "1/1 [==============================] - 8s 8s/step - loss: 28.0101 - costs: 5.4600\n",
      "Epoch 937/937\n",
      "1/1 [==============================] - 12s 12s/step - loss: 10.2068 - costs: 3.2200\n",
      "Epoch 938/938\n",
      "1/1 [==============================] - 5s 5s/step - loss: 36.2799 - costs: 5.0500\n",
      "Epoch 939/939\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.4233 - costs: 2.2300\n",
      "Epoch 940/940\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.4556 - costs: 5.0000\n",
      "Epoch 941/941\n",
      "1/1 [==============================] - 13s 13s/step - loss: 15.5441 - costs: 3.7400\n",
      "Epoch 942/942\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.9078 - costs: 3.4600\n",
      "Epoch 943/943\n",
      "1/1 [==============================] - 6s 6s/step - loss: 20.7034 - costs: 5.4000\n",
      "Epoch 944/944\n",
      "1/1 [==============================] - 7s 7s/step - loss: 28.9090 - costs: 5.7300\n",
      "Epoch 945/945\n",
      "1/1 [==============================] - 11s 11s/step - loss: 23.5904 - costs: 2.4500\n",
      "Epoch 946/946\n",
      "1/1 [==============================] - 5s 5s/step - loss: 30.0273 - costs: 3.7600\n",
      "Epoch 947/947\n",
      "1/1 [==============================] - 4s 4s/step - loss: 26.3648 - costs: 1.9600\n",
      "Epoch 948/948\n",
      "1/1 [==============================] - 3s 3s/step - loss: 39.8178 - costs: 1.9500\n",
      "Epoch 949/949\n",
      "1/1 [==============================] - 3s 3s/step - loss: 48.5497 - costs: 4.1600\n",
      "Epoch 950/950\n",
      "1/1 [==============================] - 13s 13s/step - loss: 21.5345 - costs: 4.1200\n",
      "Epoch 951/951\n",
      "1/1 [==============================] - 6s 6s/step - loss: 6.7580 - costs: 2.0600\n",
      "Epoch 952/952\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.9219 - costs: 2.1100\n",
      "Epoch 953/953\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.4653 - costs: 4.3100\n",
      "Epoch 954/954\n",
      "1/1 [==============================] - 3s 3s/step - loss: 138.4811 - costs: 8.9000\n",
      "Epoch 955/955\n",
      "1/1 [==============================] - 12s 12s/step - loss: 12.4003 - costs: 3.6400\n",
      "Epoch 956/956\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.4861 - costs: 3.6900\n",
      "Epoch 957/957\n",
      "1/1 [==============================] - 3s 3s/step - loss: 41.2845 - costs: 2.9600\n",
      "Epoch 958/958\n",
      "1/1 [==============================] - 3s 3s/step - loss: 77.9046 - costs: 6.3500\n",
      "Epoch 959/959\n",
      "1/1 [==============================] - 13s 13s/step - loss: 16.8114 - costs: 3.4900\n",
      "Epoch 960/960\n",
      "1/1 [==============================] - 5s 5s/step - loss: 36.2488 - costs: 5.0700\n",
      "Epoch 961/961\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.3682 - costs: 4.5800\n",
      "Epoch 962/962\n",
      "1/1 [==============================] - 11s 11s/step - loss: 30.5203 - costs: 5.7700\n",
      "Epoch 963/963\n",
      "1/1 [==============================] - 8s 8s/step - loss: 23.0471 - costs: 5.7200\n",
      "Epoch 964/964\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.4627 - costs: 3.4000\n",
      "Epoch 965/965\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.5010 - costs: 2.7000\n",
      "Epoch 966/966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 108.9561 - costs: 7.8200\n",
      "Epoch 967/967\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.0526 - costs: 4.2800\n",
      "Epoch 968/968\n",
      "1/1 [==============================] - 4s 4s/step - loss: 29.9185 - costs: 2.0100\n",
      "Epoch 969/969\n",
      "1/1 [==============================] - 12s 12s/step - loss: 14.6671 - costs: 1.8400\n",
      "Epoch 970/970\n",
      "1/1 [==============================] - 6s 6s/step - loss: 9.4949 - costs: 1.7600\n",
      "Epoch 971/971\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.4138 - costs: 1.6800\n",
      "Epoch 972/972\n",
      "1/1 [==============================] - 5s 5s/step - loss: 41.3253 - costs: 4.9100\n",
      "Epoch 973/973\n",
      "1/1 [==============================] - 5s 5s/step - loss: 19.9614 - costs: 4.9900\n",
      "Epoch 974/974\n",
      "1/1 [==============================] - 13s 13s/step - loss: 29.9819 - costs: 4.7300\n",
      "Epoch 975/975\n",
      "1/1 [==============================] - 5s 5s/step - loss: 6.0532 - costs: 2.2000\n",
      "Epoch 976/976\n",
      "1/1 [==============================] - 7s 7s/step - loss: 33.2486 - costs: 6.6500\n",
      "Epoch 977/977\n",
      "1/1 [==============================] - 10s 10s/step - loss: 12.4229 - costs: 2.5900\n",
      "Epoch 978/978\n",
      "1/1 [==============================] - 6s 6s/step - loss: 7.4870 - costs: 2.3800\n",
      "Epoch 979/979\n",
      "1/1 [==============================] - 3s 3s/step - loss: 51.8823 - costs: 4.2500\n",
      "Epoch 980/980\n",
      "1/1 [==============================] - 3s 3s/step - loss: 134.1894 - costs: 9.5900\n",
      "Epoch 981/981\n",
      "1/1 [==============================] - 4s 4s/step - loss: 19.4885 - costs: 2.7800\n",
      "Epoch 982/982\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.0136 - costs: 2.1100\n",
      "Epoch 983/983\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.3543 - costs: 3.7200\n",
      "Epoch 984/984\n",
      "1/1 [==============================] - 5s 5s/step - loss: 30.0716 - costs: 4.4100\n",
      "Epoch 985/985\n",
      "1/1 [==============================] - 12s 12s/step - loss: 43.9940 - costs: 6.5400\n",
      "Epoch 986/986\n",
      "1/1 [==============================] - 5s 5s/step - loss: 12.1703 - costs: 3.6400\n",
      "Epoch 987/987\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.4663 - costs: 3.8800\n",
      "Epoch 988/988\n",
      "1/1 [==============================] - 7s 7s/step - loss: 29.5378 - costs: 5.9400\n",
      "Epoch 989/989\n",
      "1/1 [==============================] - 13s 13s/step - loss: 18.3063 - costs: 4.2700\n",
      "Epoch 990/990\n",
      "1/1 [==============================] - 3s 3s/step - loss: 76.5916 - costs: 6.0700\n",
      "Epoch 991/991\n",
      "1/1 [==============================] - 3s 3s/step - loss: 80.6789 - costs: 4.0800\n",
      "Epoch 992/992\n",
      "1/1 [==============================] - 6s 6s/step - loss: 13.3742 - costs: 3.8500\n",
      "Epoch 993/993\n",
      "1/1 [==============================] - 6s 6s/step - loss: 51.5123 - costs: 3.9700\n",
      "Epoch 994/994\n",
      "1/1 [==============================] - 9s 9s/step - loss: 12.3480 - costs: 1.9000\n",
      "Epoch 995/995\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.5800 - costs: 5.2900\n",
      "Epoch 996/996\n",
      "1/1 [==============================] - 13s 13s/step - loss: 21.2074 - costs: 4.0100\n",
      "Epoch 997/997\n",
      "1/1 [==============================] - 6s 6s/step - loss: 37.4629 - costs: 7.0000\n",
      "Epoch 998/998\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.7751 - costs: 3.6300\n",
      "Epoch 999/999\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.1847 - costs: 2.4700\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 4s 4s/step - loss: 22.0819 - costs: 2.6400\n",
      "Epoch 1001/1001\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.4551 - costs: 2.4300\n",
      "Epoch 1002/1002\n",
      "1/1 [==============================] - 13s 13s/step - loss: 16.2055 - costs: 3.9500\n",
      "Epoch 1003/1003\n",
      "1/1 [==============================] - 4s 4s/step - loss: 42.1314 - costs: 4.9400\n",
      "Epoch 1004/1004\n",
      "1/1 [==============================] - 3s 3s/step - loss: 113.7454 - costs: 8.6300\n",
      "Epoch 1005/1005\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.9968 - costs: 4.1200\n",
      "Epoch 1006/1006\n",
      "1/1 [==============================] - 16s 16s/step - loss: 21.6410 - costs: 5.6200\n",
      "Epoch 1007/1007\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.0500 - costs: 6.0000\n",
      "Epoch 1008/1008\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.1432 - costs: 1.9400\n",
      "Epoch 1009/1009\n",
      "1/1 [==============================] - 7s 7s/step - loss: 13.1783 - costs: 3.3700\n",
      "Epoch 1010/1010\n",
      "1/1 [==============================] - 12s 12s/step - loss: 37.4796 - costs: 5.0700\n",
      "Epoch 1011/1011\n",
      "1/1 [==============================] - 3s 3s/step - loss: 53.1529 - costs: 3.4400\n",
      "Epoch 1012/1012\n",
      "1/1 [==============================] - 5s 5s/step - loss: 11.8261 - costs: 3.2600\n",
      "Epoch 1013/1013\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.7771 - costs: 2.8100\n",
      "Epoch 1014/1014\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.4279 - costs: 2.0100\n",
      "Epoch 1015/1015\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.2221 - costs: 3.4600\n",
      "Epoch 1016/1016\n",
      "1/1 [==============================] - 10s 10s/step - loss: 16.5232 - costs: 2.0500\n",
      "Epoch 1017/1017\n",
      "1/1 [==============================] - 8s 8s/step - loss: 20.2135 - costs: 3.3500\n",
      "Epoch 1018/1018\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.6044 - costs: 4.4600\n",
      "Epoch 1019/1019\n",
      "1/1 [==============================] - 13s 13s/step - loss: 26.3635 - costs: 5.0800\n",
      "Epoch 1020/1020\n",
      "1/1 [==============================] - 3s 3s/step - loss: 49.0725 - costs: 1.8400\n",
      "Epoch 1021/1021\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.8473 - costs: 1.7500\n",
      "Epoch 1022/1022\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.3367 - costs: 1.7400\n",
      "Epoch 1023/1023\n",
      "1/1 [==============================] - 7s 7s/step - loss: 19.3928 - costs: 4.9700\n",
      "Epoch 1024/1024\n",
      "1/1 [==============================] - 10s 10s/step - loss: 27.5689 - costs: 3.8700\n",
      "Epoch 1025/1025\n",
      "1/1 [==============================] - 9s 9s/step - loss: 18.7086 - costs: 2.0700\n",
      "Epoch 1026/1026\n",
      "1/1 [==============================] - 3s 3s/step - loss: 78.8880 - costs: 6.4400\n",
      "Epoch 1027/1027\n",
      "1/1 [==============================] - 3s 3s/step - loss: 74.7056 - costs: 6.1000\n",
      "Epoch 1028/1028\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.0740 - costs: 1.8600\n",
      "Epoch 1029/1029\n",
      "1/1 [==============================] - 3s 3s/step - loss: 44.5199 - costs: 3.7600\n",
      "Epoch 1030/1030\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.7385 - costs: 3.1400\n",
      "Epoch 1031/1031\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.0698 - costs: 4.6900\n",
      "Epoch 1032/1032\n",
      "1/1 [==============================] - 6s 6s/step - loss: 12.0020 - costs: 2.2100\n",
      "Epoch 1033/1033\n",
      "1/1 [==============================] - 13s 13s/step - loss: 20.2893 - costs: 5.9100\n",
      "Epoch 1034/1034\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.0381 - costs: 5.7000\n",
      "Epoch 1035/1035\n",
      "1/1 [==============================] - 7s 7s/step - loss: 18.2006 - costs: 3.6100\n",
      "Epoch 1036/1036\n",
      "1/1 [==============================] - 12s 12s/step - loss: 18.2127 - costs: 2.1100\n",
      "Epoch 1037/1037\n",
      "1/1 [==============================] - 4s 4s/step - loss: 28.6632 - costs: 2.0700\n",
      "Epoch 1038/1038\n",
      "1/1 [==============================] - 3s 3s/step - loss: 48.0854 - costs: 2.0000\n",
      "Epoch 1039/1039\n",
      "1/1 [==============================] - 5s 5s/step - loss: 36.9604 - costs: 5.4600\n",
      "Epoch 1040/1040\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.5079 - costs: 3.5500\n",
      "Epoch 1041/1041\n",
      "1/1 [==============================] - 11s 11s/step - loss: 9.8119 - costs: 3.3300\n",
      "Epoch 1042/1042\n",
      "1/1 [==============================] - 7s 7s/step - loss: 29.7275 - costs: 5.8500\n",
      "Epoch 1043/1043\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.6724 - costs: 1.6500\n",
      "Epoch 1044/1044\n",
      "1/1 [==============================] - 13s 13s/step - loss: 13.1861 - costs: 3.5300\n",
      "Epoch 1045/1045\n",
      "1/1 [==============================] - 4s 4s/step - loss: 11.6196 - costs: 3.5900\n",
      "Epoch 1046/1046\n",
      "1/1 [==============================] - 4s 4s/step - loss: 30.6490 - costs: 3.9700\n",
      "Epoch 1047/1047\n",
      "1/1 [==============================] - 3s 3s/step - loss: 30.5454 - costs: 2.3900\n",
      "Epoch 1048/1048\n",
      "1/1 [==============================] - 5s 5s/step - loss: 48.7996 - costs: 5.8000\n",
      "Epoch 1049/1049\n",
      "1/1 [==============================] - 9s 9s/step - loss: 76.2221 - costs: 5.9200\n",
      "Epoch 1050/1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step - loss: 11.5562 - costs: 3.2800\n",
      "Epoch 1051/1051\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.1451 - costs: 4.1100\n",
      "Epoch 1052/1052\n",
      "1/1 [==============================] - 3s 3s/step - loss: 45.8003 - costs: 3.5100\n",
      "Epoch 1053/1053\n",
      "1/1 [==============================] - 11s 11s/step - loss: 25.9758 - costs: 1.7800\n",
      "Epoch 1054/1054\n",
      "1/1 [==============================] - 5s 5s/step - loss: 10.3761 - costs: 3.1500\n",
      "Epoch 1055/1055\n",
      "1/1 [==============================] - 7s 7s/step - loss: 16.0484 - costs: 3.1300\n",
      "Epoch 1056/1056\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.7658 - costs: 1.8000\n",
      "Epoch 1057/1057\n",
      "1/1 [==============================] - 13s 13s/step - loss: 12.4681 - costs: 1.8900\n",
      "Epoch 1058/1058\n",
      "1/1 [==============================] - 6s 6s/step - loss: 17.9035 - costs: 4.5900\n",
      "Epoch 1059/1059\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.5363 - costs: 2.5900\n",
      "Epoch 1060/1060\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.5555 - costs: 1.8100\n",
      "Epoch 1061/1061\n",
      "1/1 [==============================] - 13s 13s/step - loss: 25.2059 - costs: 4.9800\n",
      "Epoch 1062/1062\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.8482 - costs: 1.7900\n",
      "Epoch 1063/1063\n",
      "1/1 [==============================] - 5s 5s/step - loss: 35.2966 - costs: 4.9700\n",
      "Epoch 1064/1064\n",
      "1/1 [==============================] - 12s 12s/step - loss: 23.8728 - costs: 4.9000\n",
      "Epoch 1065/1065\n",
      "1/1 [==============================] - 8s 8s/step - loss: 6.9687 - costs: 1.7400\n",
      "Epoch 1066/1066\n",
      "1/1 [==============================] - 5s 5s/step - loss: 9.5369 - costs: 3.0100\n",
      "Epoch 1067/1067\n",
      "1/1 [==============================] - 7s 7s/step - loss: 11.6656 - costs: 3.1900\n",
      "Epoch 1068/1068\n",
      "1/1 [==============================] - 5s 5s/step - loss: 13.8709 - costs: 4.2100\n",
      "Epoch 1069/1069\n",
      "1/1 [==============================] - 4s 4s/step - loss: 35.9576 - costs: 1.8700\n",
      "Epoch 1070/1070\n",
      "1/1 [==============================] - 10s 10s/step - loss: 7.9051 - costs: 1.7000\n",
      "Epoch 1071/1071\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.4057 - costs: 1.7200\n",
      "Epoch 1072/1072\n",
      "1/1 [==============================] - 5s 5s/step - loss: 26.0896 - costs: 3.3800\n",
      "Epoch 1073/1073\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7.5730 - costs: 2.7400\n",
      "Epoch 1074/1074\n",
      "1/1 [==============================] - 6s 6s/step - loss: 6.3766 - costs: 1.7500\n",
      "Epoch 1075/1075\n",
      "1/1 [==============================] - 9s 9s/step - loss: 79.3433 - costs: 5.8200\n",
      "Epoch 1076/1076\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.6801 - costs: 3.4300\n",
      "Epoch 1077/1077\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.3507 - costs: 3.2900\n",
      "Epoch 1078/1078\n",
      "1/1 [==============================] - 3s 3s/step - loss: 44.5666 - costs: 3.5900\n",
      "Epoch 1079/1079\n",
      "1/1 [==============================] - 12s 12s/step - loss: 12.6855 - costs: 1.7000\n",
      "Epoch 1080/1080\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.4292 - costs: 4.5300\n"
     ]
    }
   ],
   "source": [
    "ep=540\n",
    "for i in range(30):#range(50)\n",
    "    zipped_list = list(zip(x_train_list,y_train_list))\n",
    "    random.shuffle(zipped_list)\n",
    "    x_train_list, y_train_list = zip(*zipped_list)\n",
    "    for j in range(len(x_train_list)):\n",
    "        history = Transformer.fit(x_train_list[j], y_train_list[j], shuffle=True, batch_size=128000, epochs=ep+1, initial_epoch=ep) #validation_data=(x_val_list[j],y_val_list[j])) #callbacks=[my_val_callback]\n",
    "        ep = history.epoch[-1]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a4b65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6\n",
      "413/413 [==============================] - 234s 565ms/step - loss: 8.5292 - costs: 1.5604\n",
      "Epoch 7/7\n",
      "79/79 [==============================] - 62s 782ms/step - loss: 3.7060 - costs: 1.2265\n",
      "Epoch 8/8\n",
      "313/313 [==============================] - 131s 419ms/step - loss: 12.5189 - costs: 0.9045\n",
      "Epoch 9/9\n",
      "385/385 [==============================] - 189s 492ms/step - loss: 10.3162 - costs: 1.2449\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 60s 755ms/step - loss: 3.0238 - costs: 0.9409\n",
      "Epoch 11/11\n",
      "383/383 [==============================] - 185s 482ms/step - loss: 3.9567 - costs: 0.4766\n",
      "Epoch 12/12\n",
      "79/79 [==============================] - 60s 759ms/step - loss: 2.9786 - costs: 0.9118\n",
      "Epoch 13/13\n",
      "278/278 [==============================] - 189s 679ms/step - loss: 1.4638 - costs: 0.4535\n",
      "Epoch 14/14\n",
      "313/313 [==============================] - 131s 418ms/step - loss: 21.9635 - costs: 1.5540\n",
      "Epoch 15/15\n",
      "210/210 [==============================] - 146s 696ms/step - loss: 4.8636 - costs: 1.4544\n",
      "Epoch 16/16\n",
      "313/313 [==============================] - 128s 410ms/step - loss: 7.2331 - costs: 0.4604\n",
      "Epoch 17/17\n",
      "408/408 [==============================] - 254s 623ms/step - loss: 3.6675 - costs: 1.0246\n",
      "Epoch 18/18\n",
      "346/346 [==============================] - 216s 625ms/step - loss: 5.6719 - costs: 1.4875\n",
      "Epoch 19/19\n",
      "416/416 [==============================] - 227s 545ms/step - loss: 2.4914 - costs: 0.4487\n",
      "Epoch 20/20\n",
      "261/261 [==============================] - 180s 692ms/step - loss: 2.9167 - costs: 0.9137\n",
      "Epoch 21/21\n",
      "411/411 [==============================] - 252s 614ms/step - loss: 1.4989 - costs: 0.3944\n",
      "Epoch 22/22\n",
      "391/391 [==============================] - 190s 486ms/step - loss: 7.0406 - costs: 0.9149\n",
      "Epoch 23/23\n",
      "454/454 [==============================] - 253s 557ms/step - loss: 4.2948 - costs: 0.8455\n",
      "Epoch 24/24\n",
      "413/413 [==============================] - 230s 557ms/step - loss: 7.4198 - costs: 1.3915\n",
      "Epoch 25/25\n",
      "454/454 [==============================] - 252s 556ms/step - loss: 4.3193 - costs: 0.8374\n",
      "Epoch 26/26\n",
      "411/411 [==============================] - 253s 616ms/step - loss: 1.7462 - costs: 0.4567\n",
      "Epoch 27/27\n",
      "210/210 [==============================] - 146s 697ms/step - loss: 4.9485 - costs: 1.5758\n",
      "Epoch 28/28\n",
      "313/313 [==============================] - 132s 422ms/step - loss: 19.6865 - costs: 1.3830\n",
      "Epoch 29/29\n",
      "79/79 [==============================] - 60s 761ms/step - loss: 4.3975 - costs: 1.3901\n",
      "Epoch 30/30\n",
      "278/278 [==============================] - 188s 678ms/step - loss: 1.8013 - costs: 0.5299\n",
      "Epoch 31/31\n",
      "385/385 [==============================] - 188s 487ms/step - loss: 10.9508 - costs: 1.3222\n",
      "Epoch 32/32\n",
      "261/261 [==============================] - 181s 692ms/step - loss: 3.1755 - costs: 0.9727\n",
      "Epoch 33/33\n",
      "313/313 [==============================] - 131s 418ms/step - loss: 11.8795 - costs: 0.8345\n",
      "Epoch 34/34\n",
      "313/313 [==============================] - 129s 411ms/step - loss: 6.3550 - costs: 0.4127\n",
      "Epoch 35/35\n",
      "383/383 [==============================] - 183s 479ms/step - loss: 2.9195 - costs: 0.3683\n",
      "Epoch 36/36\n",
      "391/391 [==============================] - 191s 487ms/step - loss: 6.4078 - costs: 0.8399\n",
      "Epoch 37/37\n",
      "346/346 [==============================] - 217s 626ms/step - loss: 5.5020 - costs: 1.4439\n",
      "Epoch 38/38\n",
      "416/416 [==============================] - 228s 547ms/step - loss: 2.3698 - costs: 0.4417\n",
      "Epoch 39/39\n",
      "408/408 [==============================] - 255s 626ms/step - loss: 3.3589 - costs: 0.9229\n",
      "Epoch 40/40\n",
      "79/79 [==============================] - 59s 744ms/step - loss: 1.4772 - costs: 0.3922\n",
      "Epoch 41/41\n",
      "79/79 [==============================] - 60s 764ms/step - loss: 4.6527 - costs: 1.4124\n",
      "Epoch 42/42\n",
      "79/79 [==============================] - 60s 760ms/step - loss: 2.1345 - costs: 0.6853\n",
      "Epoch 43/43\n",
      "454/454 [==============================] - 253s 557ms/step - loss: 4.1530 - costs: 0.8338\n",
      "Epoch 44/44\n",
      "261/261 [==============================] - 181s 695ms/step - loss: 2.6687 - costs: 0.8827\n",
      "Epoch 45/45\n",
      "278/278 [==============================] - 190s 682ms/step - loss: 1.3039 - costs: 0.3931\n",
      "Epoch 46/46\n",
      "346/346 [==============================] - 217s 627ms/step - loss: 6.0927 - costs: 1.5752\n",
      "Epoch 47/47\n",
      "79/79 [==============================] - 59s 748ms/step - loss: 2.3778 - costs: 0.6335\n",
      "Epoch 48/48\n",
      "313/313 [==============================] - 131s 419ms/step - loss: 15.6780 - costs: 1.1710\n",
      "Epoch 49/49\n",
      "411/411 [==============================] - 253s 617ms/step - loss: 1.8941 - costs: 0.4880\n",
      "Epoch 50/50\n",
      "416/416 [==============================] - 228s 548ms/step - loss: 1.8328 - costs: 0.3641\n",
      "Epoch 51/51\n",
      "391/391 [==============================] - 190s 486ms/step - loss: 6.5914 - costs: 0.8421\n",
      "Epoch 52/52\n",
      "413/413 [==============================] - 231s 560ms/step - loss: 6.9481 - costs: 1.3031\n",
      "Epoch 53/53\n",
      "79/79 [==============================] - 60s 764ms/step - loss: 3.5030 - costs: 1.1971\n",
      "Epoch 54/54\n",
      "383/383 [==============================] - 184s 481ms/step - loss: 3.5071 - costs: 0.3942\n",
      "Epoch 55/55\n",
      "313/313 [==============================] - 132s 421ms/step - loss: 19.2730 - costs: 1.3091\n",
      "Epoch 56/56\n",
      "210/210 [==============================] - 146s 695ms/step - loss: 4.6220 - costs: 1.4190\n",
      "Epoch 57/57\n",
      "385/385 [==============================] - 189s 491ms/step - loss: 9.2835 - costs: 1.1410\n",
      "Epoch 58/58\n",
      "408/408 [==============================] - 256s 628ms/step - loss: 3.3763 - costs: 0.9277\n",
      "Epoch 59/59\n",
      "313/313 [==============================] - 129s 414ms/step - loss: 5.7909 - costs: 0.3863\n",
      "Epoch 60/60\n",
      "210/210 [==============================] - 147s 700ms/step - loss: 4.9735 - costs: 1.4859\n",
      "Epoch 61/61\n",
      "391/391 [==============================] - 191s 487ms/step - loss: 5.9450 - costs: 0.7670\n",
      "Epoch 62/62\n",
      "278/278 [==============================] - 190s 682ms/step - loss: 1.6021 - costs: 0.4749\n",
      "Epoch 63/63\n",
      "411/411 [==============================] - 253s 617ms/step - loss: 1.2974 - costs: 0.3634\n",
      "Epoch 64/64\n",
      "408/408 [==============================] - 257s 629ms/step - loss: 3.3493 - costs: 0.9473\n",
      "Epoch 65/65\n",
      "313/313 [==============================] - 129s 411ms/step - loss: 5.6228 - costs: 0.3935\n",
      "Epoch 66/66\n",
      "454/454 [==============================] - 254s 560ms/step - loss: 4.1607 - costs: 0.8475\n",
      "Epoch 67/67\n",
      "416/416 [==============================] - 229s 550ms/step - loss: 1.8562 - costs: 0.3569\n",
      "Epoch 68/68\n",
      "413/413 [==============================] - 232s 562ms/step - loss: 7.4519 - costs: 1.3828\n",
      "Epoch 69/69\n",
      "79/79 [==============================] - 61s 776ms/step - loss: 3.5285 - costs: 1.3027\n",
      "Epoch 70/70\n",
      "385/385 [==============================] - 190s 492ms/step - loss: 9.6687 - costs: 1.2132\n",
      "Epoch 71/71\n",
      "383/383 [==============================] - 185s 483ms/step - loss: 3.7410 - costs: 0.4503\n",
      "Epoch 72/72\n",
      "79/79 [==============================] - 60s 762ms/step - loss: 2.5950 - costs: 0.8387\n",
      "Epoch 73/73\n",
      "261/261 [==============================] - 182s 699ms/step - loss: 2.5853 - costs: 0.8707\n",
      "Epoch 74/74\n",
      "313/313 [==============================] - 132s 422ms/step - loss: 18.2227 - costs: 1.3182\n",
      "Epoch 75/75\n",
      "313/313 [==============================] - 131s 420ms/step - loss: 10.2989 - costs: 0.7203\n",
      "Epoch 76/76\n",
      "346/346 [==============================] - 218s 631ms/step - loss: 5.3124 - costs: 1.3744\n",
      "Epoch 77/77\n",
      "79/79 [==============================] - 59s 748ms/step - loss: 2.5825 - costs: 0.6391\n",
      "Epoch 78/78\n",
      "313/313 [==============================] - 129s 412ms/step - loss: 6.4608 - costs: 0.4636\n",
      "Epoch 79/79\n",
      "391/391 [==============================] - 191s 489ms/step - loss: 5.8861 - costs: 0.7916\n",
      "Epoch 80/80\n",
      "261/261 [==============================] - 183s 700ms/step - loss: 2.6861 - costs: 0.8428\n",
      "Epoch 81/81\n",
      "313/313 [==============================] - 132s 421ms/step - loss: 16.3494 - costs: 1.0919\n",
      "Epoch 82/82\n",
      "383/383 [==============================] - 184s 480ms/step - loss: 4.0385 - costs: 0.4649\n",
      "Epoch 83/83\n",
      "454/454 [==============================] - 254s 560ms/step - loss: 3.9365 - costs: 0.8189\n",
      "Epoch 84/84\n",
      "313/313 [==============================] - 131s 417ms/step - loss: 10.2147 - costs: 0.7535\n",
      "Epoch 85/85\n",
      "385/385 [==============================] - 189s 491ms/step - loss: 8.9622 - costs: 1.0905\n",
      "Epoch 86/86\n",
      "79/79 [==============================] - 60s 764ms/step - loss: 3.1034 - costs: 0.9781\n",
      "Epoch 87/87\n",
      "416/416 [==============================] - 229s 549ms/step - loss: 1.9623 - costs: 0.3713\n",
      "Epoch 88/88\n",
      "408/408 [==============================] - 256s 628ms/step - loss: 3.1419 - costs: 0.9020\n",
      "Epoch 89/89\n",
      "79/79 [==============================] - 59s 746ms/step - loss: 1.4222 - costs: 0.3678\n",
      "Epoch 90/90\n",
      "79/79 [==============================] - 60s 763ms/step - loss: 4.2295 - costs: 1.3033\n",
      "Epoch 91/91\n",
      "413/413 [==============================] - 232s 561ms/step - loss: 6.4251 - costs: 1.2403\n",
      "Epoch 92/92\n",
      "278/278 [==============================] - 190s 685ms/step - loss: 1.7480 - costs: 0.5269\n",
      "Epoch 93/93\n",
      "346/346 [==============================] - 218s 631ms/step - loss: 5.4135 - costs: 1.3771\n",
      "Epoch 94/94\n",
      "210/210 [==============================] - 147s 699ms/step - loss: 3.7466 - costs: 1.1339\n",
      "Epoch 95/95\n",
      "411/411 [==============================] - 253s 615ms/step - loss: 1.6209 - costs: 0.4153\n",
      "Epoch 96/96\n",
      "79/79 [==============================] - 61s 770ms/step - loss: 4.0966 - costs: 1.3713\n",
      "Epoch 97/97\n",
      "411/411 [==============================] - 253s 616ms/step - loss: 1.4570 - costs: 0.3756\n",
      "Epoch 98/98\n",
      "210/210 [==============================] - 147s 699ms/step - loss: 4.3838 - costs: 1.3510\n",
      "Epoch 99/99\n",
      "385/385 [==============================] - 189s 492ms/step - loss: 9.2594 - costs: 1.1374\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 129s 413ms/step - loss: 6.7808 - costs: 0.4728\n",
      "Epoch 101/101\n",
      "313/313 [==============================] - 132s 423ms/step - loss: 16.5100 - costs: 1.1272\n",
      "Epoch 102/102\n",
      "278/278 [==============================] - 191s 686ms/step - loss: 2.3538 - costs: 0.7788\n",
      "Epoch 103/103\n",
      "391/391 [==============================] - 192s 490ms/step - loss: 6.0404 - costs: 0.7920\n",
      "Epoch 104/104\n",
      "79/79 [==============================] - 60s 766ms/step - loss: 2.3825 - costs: 0.7859\n",
      "Epoch 105/105\n",
      "383/383 [==============================] - 185s 482ms/step - loss: 2.7828 - costs: 0.3250\n",
      "Epoch 106/106\n",
      "413/413 [==============================] - 232s 561ms/step - loss: 6.8468 - costs: 1.2973\n",
      "Epoch 107/107\n",
      "416/416 [==============================] - 229s 550ms/step - loss: 2.2363 - costs: 0.4128\n",
      "Epoch 108/108\n",
      "313/313 [==============================] - 132s 421ms/step - loss: 11.2517 - costs: 0.8097\n",
      "Epoch 109/109\n",
      "261/261 [==============================] - 183s 700ms/step - loss: 2.8478 - costs: 0.9239\n",
      "Epoch 110/110\n",
      "79/79 [==============================] - 59s 749ms/step - loss: 1.3055 - costs: 0.3432\n",
      "Epoch 111/111\n",
      "408/408 [==============================] - 257s 630ms/step - loss: 3.1467 - costs: 0.8794\n",
      "Epoch 112/112\n",
      "454/454 [==============================] - 254s 560ms/step - loss: 3.6551 - costs: 0.7460\n",
      "Epoch 113/113\n",
      "346/346 [==============================] - 219s 632ms/step - loss: 4.8712 - costs: 1.2778\n",
      "Epoch 114/114\n",
      "385/385 [==============================] - 190s 494ms/step - loss: 8.6816 - costs: 1.1076\n",
      "Epoch 115/115\n",
      "79/79 [==============================] - 60s 765ms/step - loss: 2.6874 - costs: 0.8475\n",
      "Epoch 116/116\n",
      "313/313 [==============================] - 131s 420ms/step - loss: 12.2704 - costs: 1.0276\n",
      "Epoch 117/117\n",
      "454/454 [==============================] - 255s 562ms/step - loss: 4.1673 - costs: 0.8879\n",
      "Epoch 118/118\n",
      "210/210 [==============================] - 148s 704ms/step - loss: 3.8626 - costs: 1.2317\n",
      "Epoch 119/119\n",
      "79/79 [==============================] - 61s 774ms/step - loss: 3.0284 - costs: 1.0954\n",
      "Epoch 120/120\n",
      "79/79 [==============================] - 59s 752ms/step - loss: 1.8119 - costs: 0.4348\n",
      "Epoch 121/121\n",
      "261/261 [==============================] - 183s 699ms/step - loss: 2.6438 - costs: 0.8726\n",
      "Epoch 122/122\n",
      "313/313 [==============================] - 132s 422ms/step - loss: 15.4936 - costs: 1.0259\n",
      "Epoch 123/123\n",
      "313/313 [==============================] - 130s 414ms/step - loss: 6.3880 - costs: 0.4577\n",
      "Epoch 124/124\n",
      "411/411 [==============================] - 254s 617ms/step - loss: 1.4156 - costs: 0.4016\n",
      "Epoch 125/125\n",
      "416/416 [==============================] - 195s 468ms/step - loss: 1.5939 - costs: 0.3082\n",
      "Epoch 126/126\n",
      "278/278 [==============================] - 155s 558ms/step - loss: 1.0749 - costs: 0.3613\n",
      "Epoch 127/127\n",
      "383/383 [==============================] - 152s 396ms/step - loss: 2.5391 - costs: 0.3311\n",
      "Epoch 128/128\n",
      "346/346 [==============================] - 175s 505ms/step - loss: 5.3926 - costs: 1.4132\n",
      "Epoch 129/129\n",
      "408/408 [==============================] - 206s 504ms/step - loss: 2.9291 - costs: 0.8406\n",
      "Epoch 130/130\n",
      "413/413 [==============================] - 187s 452ms/step - loss: 6.2203 - costs: 1.1962\n",
      "Epoch 131/131\n",
      "391/391 [==============================] - 153s 392ms/step - loss: 5.4005 - costs: 0.6900\n",
      "Epoch 132/132\n",
      "454/454 [==============================] - 204s 450ms/step - loss: 3.5466 - costs: 0.7112\n",
      "Epoch 133/133\n",
      "385/385 [==============================] - 153s 397ms/step - loss: 8.8312 - costs: 1.0978\n",
      "Epoch 134/134\n",
      "346/346 [==============================] - 175s 505ms/step - loss: 4.6196 - costs: 1.2157\n",
      "Epoch 135/135\n",
      "313/313 [==============================] - 106s 338ms/step - loss: 10.1684 - costs: 0.7333\n",
      "Epoch 136/136\n",
      "261/261 [==============================] - 146s 559ms/step - loss: 2.7642 - costs: 0.8884\n",
      "Epoch 137/137\n",
      "79/79 [==============================] - 49s 621ms/step - loss: 1.3110 - costs: 0.3678\n",
      "Epoch 138/138\n",
      "416/416 [==============================] - 188s 451ms/step - loss: 1.6623 - costs: 0.3229\n",
      "Epoch 139/139\n",
      "79/79 [==============================] - 49s 616ms/step - loss: 2.1108 - costs: 0.6866\n",
      "Epoch 140/140\n",
      "413/413 [==============================] - 186s 450ms/step - loss: 6.1085 - costs: 1.1738\n",
      "Epoch 141/141\n",
      "278/278 [==============================] - 156s 559ms/step - loss: 1.7105 - costs: 0.4912\n",
      "Epoch 142/142\n",
      "210/210 [==============================] - 118s 560ms/step - loss: 4.2601 - costs: 1.2772\n",
      "Epoch 143/143\n",
      "383/383 [==============================] - 151s 394ms/step - loss: 3.0251 - costs: 0.3725\n",
      "Epoch 144/144\n",
      "79/79 [==============================] - 49s 622ms/step - loss: 4.1644 - costs: 1.2959\n",
      "Epoch 145/145\n",
      "408/408 [==============================] - 206s 504ms/step - loss: 2.8395 - costs: 0.8043\n",
      "Epoch 146/146\n",
      "411/411 [==============================] - 208s 505ms/step - loss: 1.2425 - costs: 0.3353\n",
      "Epoch 147/147\n",
      "313/313 [==============================] - 106s 340ms/step - loss: 17.2902 - costs: 1.2169\n",
      "Epoch 148/148\n",
      "313/313 [==============================] - 107s 340ms/step - loss: 5.9645 - costs: 0.4205\n",
      "Epoch 149/149\n",
      "391/391 [==============================] - 154s 394ms/step - loss: 5.2411 - costs: 0.6746\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 117s 557ms/step - loss: 3.7743 - costs: 1.2110\n",
      "Epoch 151/151\n",
      "346/346 [==============================] - 175s 505ms/step - loss: 4.5166 - costs: 1.1943\n",
      "Epoch 152/152\n",
      "79/79 [==============================] - 49s 625ms/step - loss: 2.3019 - costs: 0.5578\n",
      "Epoch 153/153\n",
      "313/313 [==============================] - 106s 339ms/step - loss: 18.1239 - costs: 1.3053\n",
      "Epoch 154/154\n",
      "278/278 [==============================] - 156s 560ms/step - loss: 2.3155 - costs: 0.6933\n",
      "Epoch 155/155\n",
      "411/411 [==============================] - 208s 506ms/step - loss: 1.3379 - costs: 0.3746\n",
      "Epoch 156/156\n",
      "385/385 [==============================] - 152s 394ms/step - loss: 9.0134 - costs: 1.0875\n",
      "Epoch 157/157\n",
      "413/413 [==============================] - 186s 451ms/step - loss: 5.8330 - costs: 1.0909\n",
      "Epoch 158/158\n",
      "416/416 [==============================] - 188s 452ms/step - loss: 2.2258 - costs: 0.4009\n",
      "Epoch 159/159\n",
      "261/261 [==============================] - 145s 557ms/step - loss: 2.4544 - costs: 0.8241\n",
      "Epoch 160/160\n",
      "313/313 [==============================] - 106s 338ms/step - loss: 10.5324 - costs: 0.7959\n",
      "Epoch 161/161\n",
      "408/408 [==============================] - 207s 506ms/step - loss: 3.0050 - costs: 0.8884\n",
      "Epoch 162/162\n",
      "79/79 [==============================] - 49s 619ms/step - loss: 1.7911 - costs: 0.5643\n",
      "Epoch 163/163\n",
      "391/391 [==============================] - 153s 392ms/step - loss: 5.1653 - costs: 0.6745\n",
      "Epoch 164/164\n",
      "454/454 [==============================] - 204s 450ms/step - loss: 3.4527 - costs: 0.7182\n",
      "Epoch 165/165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 49s 621ms/step - loss: 3.2808 - costs: 1.0372\n",
      "Epoch 166/166\n",
      "383/383 [==============================] - 151s 394ms/step - loss: 2.8015 - costs: 0.3399\n",
      "Epoch 167/167\n",
      "313/313 [==============================] - 107s 341ms/step - loss: 4.2458 - costs: 0.3295\n",
      "Epoch 168/168\n",
      "408/408 [==============================] - 206s 504ms/step - loss: 3.1109 - costs: 0.8899\n",
      "Epoch 169/169\n",
      "413/413 [==============================] - 186s 450ms/step - loss: 6.0580 - costs: 1.1627\n",
      "Epoch 170/170\n",
      "313/313 [==============================] - 106s 340ms/step - loss: 14.8884 - costs: 1.1381\n",
      "Epoch 171/171\n",
      "261/261 [==============================] - 146s 560ms/step - loss: 2.9881 - costs: 0.9434\n",
      "Epoch 172/172\n",
      "416/416 [==============================] - 188s 452ms/step - loss: 1.7574 - costs: 0.3421\n",
      "Epoch 173/173\n",
      "313/313 [==============================] - 106s 338ms/step - loss: 10.0713 - costs: 0.7846\n",
      "Epoch 174/174\n",
      "313/313 [==============================] - 107s 342ms/step - loss: 4.7620 - costs: 0.3494\n",
      "Epoch 175/175\n",
      "79/79 [==============================] - 49s 621ms/step - loss: 1.5094 - costs: 0.4539\n",
      "Epoch 176/176\n",
      "391/391 [==============================] - 154s 394ms/step - loss: 5.6371 - costs: 0.7086\n",
      "Epoch 177/177\n",
      "385/385 [==============================] - 152s 395ms/step - loss: 8.1624 - costs: 0.9904\n",
      "Epoch 178/178\n",
      "79/79 [==============================] - 49s 618ms/step - loss: 3.3604 - costs: 1.0873\n",
      "Epoch 179/179\n",
      "79/79 [==============================] - 49s 620ms/step - loss: 1.9951 - costs: 0.6829\n",
      "Epoch 180/180\n",
      "346/346 [==============================] - 174s 503ms/step - loss: 4.5379 - costs: 1.1708\n",
      "Epoch 181/181\n",
      "411/411 [==============================] - 207s 504ms/step - loss: 1.5585 - costs: 0.3918\n",
      "Epoch 182/182\n",
      "383/383 [==============================] - 151s 395ms/step - loss: 2.3955 - costs: 0.3068\n",
      "Epoch 183/183\n",
      "278/278 [==============================] - 155s 559ms/step - loss: 1.0557 - costs: 0.3532\n",
      "Epoch 184/184\n",
      "210/210 [==============================] - 117s 559ms/step - loss: 4.2178 - costs: 1.2445\n",
      "Epoch 185/185\n",
      "454/454 [==============================] - 204s 450ms/step - loss: 3.4957 - costs: 0.7103\n",
      "Epoch 186/186\n",
      "313/313 [==============================] - 107s 341ms/step - loss: 4.7787 - costs: 0.3522\n",
      "Epoch 187/187\n",
      "313/313 [==============================] - 107s 342ms/step - loss: 15.7843 - costs: 1.0362\n",
      "Epoch 188/188\n",
      "210/210 [==============================] - 118s 560ms/step - loss: 3.8467 - costs: 1.1760\n",
      "Epoch 189/189\n",
      "385/385 [==============================] - 152s 394ms/step - loss: 7.9303 - costs: 1.0491\n",
      "Epoch 190/190\n",
      "454/454 [==============================] - 205s 451ms/step - loss: 3.5076 - costs: 0.7216\n",
      "Epoch 191/191\n",
      "313/313 [==============================] - 105s 337ms/step - loss: 9.3373 - costs: 0.6852\n",
      "Epoch 192/192\n",
      "413/413 [==============================] - 186s 451ms/step - loss: 5.8321 - costs: 1.0855\n",
      "Epoch 193/193\n",
      "79/79 [==============================] - 49s 625ms/step - loss: 2.5771 - costs: 0.5558\n",
      "Epoch 194/194\n",
      "416/416 [==============================] - 188s 452ms/step - loss: 1.6864 - costs: 0.3288\n",
      "Epoch 195/195\n",
      "408/408 [==============================] - 206s 505ms/step - loss: 2.8534 - costs: 0.8238\n",
      "Epoch 196/196\n",
      "79/79 [==============================] - 49s 618ms/step - loss: 1.7286 - costs: 0.5447\n",
      "Epoch 197/197\n",
      "391/391 [==============================] - 154s 393ms/step - loss: 5.1413 - costs: 0.6572\n",
      "Epoch 198/198\n",
      "261/261 [==============================] - 146s 559ms/step - loss: 2.3999 - costs: 0.8014\n",
      "Epoch 199/199\n",
      "79/79 [==============================] - 49s 621ms/step - loss: 2.9323 - costs: 0.9752\n",
      "Epoch 200/200\n",
      "383/383 [==============================] - 151s 395ms/step - loss: 2.6482 - costs: 0.3176\n",
      "Epoch 201/201\n",
      "411/411 [==============================] - 208s 506ms/step - loss: 1.0796 - costs: 0.3024\n",
      "Epoch 202/202\n",
      "346/346 [==============================] - 175s 505ms/step - loss: 5.0922 - costs: 1.3242\n",
      "Epoch 203/203\n",
      "278/278 [==============================] - 155s 559ms/step - loss: 1.4438 - costs: 0.4100\n",
      "Epoch 204/204\n",
      "313/313 [==============================] - 107s 341ms/step - loss: 4.9859 - costs: 0.3733\n",
      "Epoch 205/205\n",
      "79/79 [==============================] - 49s 625ms/step - loss: 1.3689 - costs: 0.4354\n",
      "Epoch 206/206\n",
      "313/313 [==============================] - 106s 340ms/step - loss: 16.6343 - costs: 1.0856\n",
      "Epoch 207/207\n",
      "408/408 [==============================] - 206s 505ms/step - loss: 3.0977 - costs: 0.8747\n",
      "Epoch 208/208\n",
      "413/413 [==============================] - 187s 453ms/step - loss: 5.7233 - costs: 1.0816\n",
      "Epoch 209/209\n",
      "278/278 [==============================] - 155s 558ms/step - loss: 1.6737 - costs: 0.4713\n",
      "Epoch 210/210\n",
      "416/416 [==============================] - 189s 454ms/step - loss: 1.5576 - costs: 0.3023\n",
      "Epoch 211/211\n",
      "411/411 [==============================] - 209s 508ms/step - loss: 1.0512 - costs: 0.2927\n",
      "Epoch 212/212\n",
      "261/261 [==============================] - 147s 562ms/step - loss: 2.3732 - costs: 0.7818\n",
      "Epoch 213/213\n",
      "385/385 [==============================] - 152s 396ms/step - loss: 8.4272 - costs: 1.0420\n",
      "Epoch 214/214\n",
      "79/79 [==============================] - 49s 620ms/step - loss: 3.1745 - costs: 1.0446\n",
      "Epoch 215/215\n",
      "383/383 [==============================] - 151s 394ms/step - loss: 2.8433 - costs: 0.3448\n",
      "Epoch 216/216\n",
      "346/346 [==============================] - 175s 507ms/step - loss: 4.8066 - costs: 1.2490\n",
      "Epoch 217/217\n",
      "79/79 [==============================] - 49s 621ms/step - loss: 2.0323 - costs: 0.6480\n",
      "Epoch 218/218\n",
      "391/391 [==============================] - 154s 394ms/step - loss: 5.0561 - costs: 0.6449\n",
      "Epoch 219/219\n",
      "210/210 [==============================] - 117s 558ms/step - loss: 3.5140 - costs: 1.0802\n",
      "Epoch 220/220\n",
      "454/454 [==============================] - 207s 456ms/step - loss: 3.3450 - costs: 0.6975\n",
      "Epoch 221/221\n",
      "313/313 [==============================] - 106s 338ms/step - loss: 10.1186 - costs: 0.7891\n",
      "Epoch 222/222\n",
      "413/413 [==============================] - 187s 453ms/step - loss: 5.7895 - costs: 1.0549\n",
      "Epoch 223/223\n",
      "391/391 [==============================] - 210s 536ms/step - loss: 4.8213 - costs: 0.6049\n",
      "Epoch 224/224\n",
      "79/79 [==============================] - 72s 907ms/step - loss: 2.1090 - costs: 0.7053\n",
      "Epoch 225/225\n",
      "408/408 [==============================] - 270s 662ms/step - loss: 2.6767 - costs: 0.7836\n",
      "Epoch 226/226\n",
      "346/346 [==============================] - 219s 634ms/step - loss: 4.3850 - costs: 1.1346\n",
      "Epoch 227/227\n",
      "313/313 [==============================] - 122s 389ms/step - loss: 9.4262 - costs: 0.7340\n",
      "Epoch 228/228\n",
      "416/416 [==============================] - 198s 476ms/step - loss: 1.9347 - costs: 0.3563\n",
      "Epoch 229/229\n",
      "383/383 [==============================] - 152s 396ms/step - loss: 2.0421 - costs: 0.2502\n",
      "Epoch 230/230\n",
      "313/313 [==============================] - 107s 340ms/step - loss: 15.6775 - costs: 1.0544\n",
      "Epoch 231/231\n",
      "79/79 [==============================] - 50s 628ms/step - loss: 3.5926 - costs: 1.1916\n",
      "Epoch 232/232\n",
      "79/79 [==============================] - 49s 622ms/step - loss: 5.1391 - costs: 1.4210\n",
      "Epoch 233/233\n",
      "411/411 [==============================] - 208s 507ms/step - loss: 1.5153 - costs: 0.4079\n",
      "Epoch 234/234\n",
      "210/210 [==============================] - 117s 559ms/step - loss: 3.9962 - costs: 1.1454\n",
      "Epoch 235/235\n",
      "385/385 [==============================] - 153s 398ms/step - loss: 7.8288 - costs: 0.9750\n",
      "Epoch 236/236\n",
      "278/278 [==============================] - 156s 563ms/step - loss: 1.7078 - costs: 0.4757\n",
      "Epoch 237/237\n",
      "261/261 [==============================] - 147s 562ms/step - loss: 2.4421 - costs: 0.7769\n",
      "Epoch 238/238\n",
      "454/454 [==============================] - 205s 452ms/step - loss: 3.3169 - costs: 0.6797\n",
      "Epoch 239/239\n",
      "313/313 [==============================] - 107s 341ms/step - loss: 4.3432 - costs: 0.2927\n",
      "Epoch 240/240\n",
      "383/383 [==============================] - 151s 395ms/step - loss: 2.0209 - costs: 0.2496\n",
      "Epoch 241/241\n",
      "416/416 [==============================] - 188s 451ms/step - loss: 1.3242 - costs: 0.2631\n",
      "Epoch 242/242\n",
      "79/79 [==============================] - 50s 629ms/step - loss: 0.8143 - costs: 0.2877\n",
      "Epoch 243/243\n",
      "313/313 [==============================] - 107s 342ms/step - loss: 4.2672 - costs: 0.2922\n",
      "Epoch 244/244\n",
      "411/411 [==============================] - 208s 506ms/step - loss: 1.1449 - costs: 0.3413\n",
      "Epoch 245/245\n",
      "313/313 [==============================] - 106s 340ms/step - loss: 16.3013 - costs: 1.0516\n",
      "Epoch 246/246\n",
      "408/408 [==============================] - 207s 506ms/step - loss: 3.0526 - costs: 0.8405\n",
      "Epoch 247/247\n",
      "454/454 [==============================] - 205s 451ms/step - loss: 3.2573 - costs: 0.6692\n",
      "Epoch 248/248\n",
      "278/278 [==============================] - 156s 561ms/step - loss: 1.2485 - costs: 0.3771\n",
      "Epoch 249/249\n",
      "79/79 [==============================] - 50s 628ms/step - loss: 3.8478 - costs: 1.1503\n",
      "Epoch 250/250\n",
      "385/385 [==============================] - 169s 439ms/step - loss: 7.8737 - costs: 0.9377\n",
      "Epoch 251/251\n",
      "346/346 [==============================] - 175s 506ms/step - loss: 4.3388 - costs: 1.1304\n",
      "Epoch 252/252\n",
      "313/313 [==============================] - 106s 339ms/step - loss: 9.1472 - costs: 0.6446\n",
      "Epoch 253/253\n",
      "79/79 [==============================] - 49s 620ms/step - loss: 2.5443 - costs: 0.7486\n",
      "Epoch 254/254\n",
      "261/261 [==============================] - 146s 558ms/step - loss: 2.2855 - costs: 0.7981\n",
      "Epoch 255/255\n",
      "371/413 [=========================>....] - ETA: 19s - loss: 5.6325 - costs: 1.0556"
     ]
    }
   ],
   "source": [
    "ep=5 \n",
    "for i in range(24):#range(50)\n",
    "    zipped_list = list(zip(x_train_list,y_train_list))\n",
    "    random.shuffle(zipped_list)\n",
    "    x_train_list, y_train_list = zip(*zipped_list)\n",
    "    for j in range(len(x_train_list)):\n",
    "        history = Transformer.fit(x_train_list[j], y_train_list[j], shuffle=True, batch_size=128, epochs=ep+1, initial_epoch=ep) #validation_data=(x_val_list[j],y_val_list[j])) #callbacks=[my_val_callback]\n",
    "        ep = history.epoch[-1]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1e296a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  Jobs  2  Machines:\n",
      "1250/1250 [==============================] - 342s 274ms/step - loss: 44.1458 - costs: 1.1294\n",
      "3  Jobs  3  Machines:\n",
      "1250/1250 [==============================] - 350s 280ms/step - loss: 131.0477 - costs: 4.8325\n",
      "3  Jobs  4  Machines:\n",
      "1250/1250 [==============================] - 332s 265ms/step - loss: 212.6674 - costs: 9.2144\n",
      "4  Jobs  2  Machines:\n",
      "1563/1563 [==============================] - 463s 296ms/step - loss: 13.8030 - costs: 0.4894\n",
      "4  Jobs  3  Machines:\n",
      "1563/1563 [==============================] - 451s 288ms/step - loss: 52.7525 - costs: 2.2059\n",
      "4  Jobs  4  Machines:\n",
      "1563/1563 [==============================] - 461s 295ms/step - loss: 94.6736 - costs: 5.1114\n",
      "5  Jobs  2  Machines:\n",
      "1875/1875 [==============================] - 607s 324ms/step - loss: 5.4297 - costs: 0.3785\n",
      "5  Jobs  3  Machines:\n",
      "1875/1875 [==============================] - 613s 327ms/step - loss: 25.4819 - costs: 1.4054\n",
      "5  Jobs  4  Machines:\n",
      "1875/1875 [==============================] - 643s 343ms/step - loss: 51.2660 - costs: 3.6943\n",
      "6  Jobs  2  Machines:\n",
      "2188/2188 [==============================] - 783s 358ms/step - loss: 2.5425 - costs: 0.3428\n",
      "6  Jobs  3  Machines:\n",
      "2188/2188 [==============================] - 2888s 1s/step - loss: 14.5750 - costs: 1.2552\n",
      "6  Jobs  4  Machines:\n",
      "2188/2188 [==============================] - 826s 378ms/step - loss: 31.3414 - costs: 3.1876\n",
      "7  Jobs  2  Machines:\n",
      "2500/2500 [==============================] - 1032s 413ms/step - loss: 1.5145 - costs: 0.3598\n",
      "7  Jobs  3  Machines:\n",
      "2500/2500 [==============================] - 1086s 434ms/step - loss: 9.3981 - costs: 1.2077\n",
      "7  Jobs  4  Machines:\n",
      "2500/2500 [==============================] - 1113s 445ms/step - loss: 21.1148 - costs: 3.2743\n",
      "8  Jobs  2  Machines:\n",
      "313/313 [==============================] - 152s 486ms/step - loss: 1.1676 - costs: 0.3763\n",
      "8  Jobs  3  Machines:\n",
      "313/313 [==============================] - 154s 490ms/step - loss: 6.7243 - costs: 1.4174\n",
      "8  Jobs  4  Machines:\n",
      "313/313 [==============================] - 152s 486ms/step - loss: 14.3611 - costs: 3.0630\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(x_val_list)):\n",
    "    print(str(j//3+3), \" Jobs \", str(j%3+2), \" Machines:\")\n",
    "    performance = Transformer.evaluate(x_val_list[j], y_val_list[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22324b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer.save('Transformer_no_batches.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7045b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer = keras.models.load_model('Transformer.h5', custom_objects={'FeedForward': FeedForward, 'Pointer': Pointer, 'TransformerLayer': TransformerLayer, 'Merge': Merge, 'AddZeroLine': AddZeroLine, 'MSE_with_Softmax': MSE_with_Softmax, 'costs':costs})\n",
    "Transformer.run_eagerly = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
